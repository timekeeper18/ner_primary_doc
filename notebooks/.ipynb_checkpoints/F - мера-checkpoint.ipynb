{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "\n",
    "df_ner = pd.read_excel(r\"C:\\Users\\Admin\\Desktop\\NER_TEST.xlsx\")\n",
    "\n",
    "org_text = df_ner['TEXT']\n",
    "correct_result = df_ner['ORG_CORRECT']\n",
    "dp_result = df_ner['ORG_DP']\n",
    "nt_result = df_ner['ORG_NATASHA']\n",
    "\n",
    "new_corret_result = []\n",
    "for row in correct_result:\n",
    "    row_cor = ast.literal_eval(row)\n",
    "    row_cor = [[''.join(re.findall('[A-Za-zА-Яа-я0-9]+', i[1].lower().strip()))] for i in row_cor if 'ORG' in i or 'PER' in i]\n",
    "    new_corret_result.append(row_cor)\n",
    "    \n",
    "new_dp_result = []\n",
    "for row in dp_result:\n",
    "    row_cor = ast.literal_eval(row)\n",
    "    row_cor = [[''.join(re.findall('[A-Za-zА-Яа-я0-9]+', i[1].lower().strip()))] for i in row_cor if 'ORG' in i or 'PER' in i]\n",
    "    new_dp_result.append(row_cor)\n",
    "\n",
    "new_nt_result = []\n",
    "for row in nt_result:\n",
    "    row_cor = ast.literal_eval(row)\n",
    "    row_cor = [[''.join(re.findall('[A-Za-zА-Яа-я0-9]+', i[1].lower().strip()))] for i in row_cor if 'ORG' in i or 'PER' in i]\n",
    "    new_nt_result.append(row_cor)\n",
    "    \n",
    "correct_result = new_corret_result\n",
    "dp_result = new_dp_result\n",
    "nt_result = new_nt_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_info_dict(org_string, tag_correct, tag_ner):\n",
    "    true = []\n",
    "    pred = []\n",
    "    \n",
    "    org_string = ''.join(re.findall('[A-Za-zА-Яа-я0-9]+', org_string.lower().strip()))\n",
    "    \n",
    "    for i in tag_correct:\n",
    "        if isinstance(i, list):\n",
    "            i = ' '.join(i)\n",
    "        try:\n",
    "            start_label = org_string.index(i.lower().strip())\n",
    "            stop_label = start_label + len(i)\n",
    "            true.append({'label': 'ORG', 'start': start_label, 'end': stop_label})\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    for j in tag_ner:\n",
    "        if isinstance(j, list):\n",
    "            j = ' '.join(j)\n",
    "        j = re.sub('\\s{1,}', '', j)\n",
    "        try:\n",
    "            start_label = org_string.index(j.lower().strip())\n",
    "            stop_label = start_label + len(j)\n",
    "            pred.append({'label': 'ORG', 'start': start_label, 'end': stop_label})\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return true, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true_tag_all = []\n",
    "pred_tag_all = []\n",
    "for index in range(0, len(df_ner)):\n",
    "    true_pos, pred_pos = get_tag_info_dict(org_text[index], correct_result[index], nt_result[index])\n",
    "    true_tag_all.append(true_pos)\n",
    "    pred_tag_all.append(pred_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct': 3739,\n",
       " 'incorrect': 20918,\n",
       " 'partial': 0,\n",
       " 'missed': 10435,\n",
       " 'spurious': 7137,\n",
       " 'possible': 35092,\n",
       " 'actual': 31794,\n",
       " 'precision': 0.11760080518336793,\n",
       " 'recall': 0.1065485010828679,\n",
       " 'f1': 0.1118021708578776}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nervaluate import Evaluator\n",
    "\n",
    "evaluator = Evaluator(true_tag_all, pred_tag_all, tags=['ORG', 'PER'])\n",
    "\n",
    "results, results_per_tag = evaluator.evaluate()\n",
    "\n",
    "results['exact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
