{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка dataset для обучение ner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>pipeline:\n",
    "    1. подготовка исходных данных (см. ORG_parser.ipynb)\n",
    "    2. подготовка шаблонов c тэгами для вставки значений (https://docs.google.com/spreadsheets/d/1YP7hZrTXd9orCLgMyl6ra-eK1eQaY8QPwLYqdaAfm8Y/edit#gid=1600051499)\n",
    "    3. подготовка кода генерации случайных шаблонов\n",
    "    4. подготовка кода добавления шумов и удаления сущностей случайным образом\n",
    "    5. генерация строк с заполенными значениями и BIO-разметка с сохранением в файл: один токен = одна строка формата: \"язык:токен тэг\\n\". Разделитель между предложениями - пустая строка\n",
    "    \n",
    "Набор NER-тэгов:\n",
    "    ORG - наименование организации\n",
    "    PER - ФИО физического лица, либо титул (граф, царь...) и ФИО\n",
    "    LOC - адрес, включая индекс, республику/область/край, город, номер дома и номер офиса/квартиры\n",
    "    INNKPP - инн/кпп организации или инн индивидуального предпринимателя\n",
    "    RSKS - расчетные и кор счета\n",
    "    STAT - коды статистики: ОКПО, ОКОГУ, ОКОПФ, ОКФС, ОКВЭД, ОКТМО + БИК банка и т.п.    \n",
    "Примеры шаблонов:\n",
    "Исполнитель [ORG] ИНН/КПП [INN]/[KPP] р/с [RS] банк [BANK] БИК [BIK] адрес [LOC] тел. [TEL]\n",
    "Исполнитель [ORG] ИНН/КПП [INN]/[KPP] адрес [LOC] банк [BANK] БИК [BIK] к/с [KS] тел. [TEL]\n",
    "{ORG: ООО Ромашка\n",
    "INN: 1221323434\n",
    "KPP: 121313}\n",
    "\n",
    "\n",
    "    BIO-словарь = соответсвие сущностей тэгам bio-разметки (ex [ORG]=ORG, [INN] = INNKPP)\"</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import re\n",
    "from collections import Counter\n",
    "from razdel import tokenize\n",
    "import sys\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "sys.path.insert(0, \"../src\")\n",
    "import string\n",
    "import locale\n",
    "import datetime\n",
    "\n",
    "# прописываем локаль, чтобы даты писались на русском языке\n",
    "locale.setlocale(locale.LC_TIME, 'ru_RU.UTF-8')\n",
    "\n",
    "# список символов для случайной выборки шумов\n",
    "characters = string.ascii_letters + string.digits + string.punctuation + 'ёйцукенгшщзхъфывапролджэячсмитьбюЁЙЦУКЕНГШЩЗХЪФЫВАПРОЛДЖЭЯЧСМИТЬБЮ,'\n",
    "\n",
    "\n",
    "from generate_tag_value import GenerateTagValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Словарь тэгов: ключи = тэги в шаблоне, значения = BIO-тэги\n",
    "\n",
    "tags = {'[ORG]': 'ORG',\n",
    "        '[BANK]': 'ORG',\n",
    "        '[INN]': 'INNKPP',\n",
    "        '[KPP]': 'INNKPP',\n",
    "        '[RS]': 'RSKS',\n",
    "        '[KS]': 'RSKS',\n",
    "        '[LOC]': 'LOC',\n",
    "        '[PER]': 'PER',\n",
    "        '[BIK]': 'STAT',\n",
    "        '[TEL]': 'STAT',\n",
    "        '[OKPO]': 'STAT',\n",
    "        '[OKATO]': 'STAT',\n",
    "        '[OKTMO]': 'STAT'        \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ru:За\\tO\\nru:образцовое\\tO\\nru:выполнение\\tO\\nru:заданий\\tO\\nru:командования\\tO\\nru:в\\tO\\nru:боях\\tO\\nru:с\\tO\\nru:немецкими\\tO\\nru:захватчиками\\tO\\nru:,\\tO\\nru:за\\tO\\nru:овладение\\tO\\nru:городом\\tO\\nru:Демблин\\tB-LOC\\nru:и\\tO\\nru:проявленные\\tO\\nru:при\\tO\\nru:этом\\tO\\nru:доблесть\\tO\\nru:и\\tO\\nru:мужество\\tO\\nru:.\\tO\\n\\nru:Стадион\\tB-LOC\\nru:имени\\tI-LOC\\nru:С.\\tI-LOC\\nru:Дарюса\\tI-LOC\\nru:и\\tI-LOC\\nru:С.\\tI-LOC\\nru:Гиренаса\\tI-LOC\\n\\nru:Майкл\\tB-PER\\nru:Томас\\tI-PER\\nru:(\\tO\\nru:1987—1991\\tO\\nru:)\\tO\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#пример BIO-разметки\n",
    "\"\"\"ru:За\tO\n",
    "ru:образцовое\tO\n",
    "ru:выполнение\tO\n",
    "ru:заданий\tO\n",
    "ru:командования\tO\n",
    "ru:в\tO\n",
    "ru:боях\tO\n",
    "ru:с\tO\n",
    "ru:немецкими\tO\n",
    "ru:захватчиками\tO\n",
    "ru:,\tO\n",
    "ru:за\tO\n",
    "ru:овладение\tO\n",
    "ru:городом\tO\n",
    "ru:Демблин\tB-LOC\n",
    "ru:и\tO\n",
    "ru:проявленные\tO\n",
    "ru:при\tO\n",
    "ru:этом\tO\n",
    "ru:доблесть\tO\n",
    "ru:и\tO\n",
    "ru:мужество\tO\n",
    "ru:.\tO\n",
    "\n",
    "ru:Стадион\tB-LOC\n",
    "ru:имени\tI-LOC\n",
    "ru:С.\tI-LOC\n",
    "ru:Дарюса\tI-LOC\n",
    "ru:и\tI-LOC\n",
    "ru:С.\tI-LOC\n",
    "ru:Гиренаса\tI-LOC\n",
    "\n",
    "ru:Майкл\tB-PER\n",
    "ru:Томас\tI-PER\n",
    "ru:(\tO\n",
    "ru:1987—1991\tO\n",
    "ru:)\tO\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример \n",
    "entities = {'[ORG]': ['ГАРАЖНО-СТРОИТЕЛЬНЫЙ КООПЕРАТИВ \"АСС\"'],\n",
    "            '[BANK]': ['ПАО АКБ \"1Банк\"'],\n",
    "            '[INN]': ['7609017469'],\n",
    "            '[KPP]': ['760901001'],\n",
    "            '[RS]': ['40702810124000011658'],\n",
    "            '[KS]': ['30101810500000000976'],\n",
    "            '[LOC]': ['191144, г Санкт-Петербург, Центральный р-н, Дегтярный пер, д 11 литер а',\n",
    "                      '191144, г Санкт-Петербург, Центральный р-н, Дегтярный пер, д 11 литер а'],\n",
    "            '[PER]': ['Янова Оксана Вячеславовна'],\n",
    "            '[BIK]': ['044525976'],\n",
    "            '[TEL]': ['+7 (812) 748-2777'],\n",
    "            '[OKPO]': ['89041828'],\n",
    "            '[OKATO]': ['40278562000'],\n",
    "            '[OKTMO]': ['40349000']\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Словарь ключевиков и их синонимов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные ниже используются для аугментации обучающих текстов: разное написание ключевых слов,\n",
    "генерация шаблонов со случайным порядком тегов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В списке шаблонов встречаются только Исполнитель,\n",
    "# потому под синонимами Исполнителю объединяем и Заказчика и Подрядчика...\n",
    "kw = {'БИК': ['БИК', 'БИК Банка', ''],\n",
    "     'Заказчик': ['Заказчик', 'Плательщик', 'Покупатель', 'Зак-чик', 'Инвестор', \n",
    "                  'Клиент', 'З-чик', 'Генподрядчик', 'Подрядчик', 'Получатель', ''],\n",
    "     'ИНН': ['ИНН', 'ИНН [Заказчик]', 'ИНН [Исполнит]', ''],\n",
    "      \n",
    "     'Исполнитель': ['Исполнитель', 'Подрядчик', 'Поставщик', 'П-щик', 'Исп-тель', 'Субподрядчик', '',\n",
    "                    'Заказчик', 'Плательщик', 'Покупатель', 'Зак-чик', 'Инвестор', \n",
    "                    'Клиент', 'З-чик', 'Генподрядчик', 'Подрядчик', 'Получатель','Лицензиат','Лицензиар'],\n",
    "      \n",
    "    'Исполнит': ['Исполнитель', 'Подрядчик', 'Поставщик', 'П-щик', 'Исп-тель', 'Субподрядчик', ''],\n",
    "      \n",
    "     'КПП': ['КПП', 'КПП [Заказчик]', 'КПП [Исполнит]', ''],\n",
    "     'Подрядчик': ['Исполнитель', 'Подрядчик', 'Поставщик', 'П-щик', 'Исп-тель', 'Субподрядчик', ''],\n",
    "     'Подрядчика': ['Исполнителя', 'Подрядчика', 'Поставщика', 'П-щика', 'Исп-теля', 'Субподрядчика'],\n",
    "      \n",
    "     'адрес': ['Адрес','Адрес [Исполнит]', 'Адрес [Заказчик]', 'Адрес банка', 'Адрес банка [Исполнит]',\n",
    "               'Адрес банка [Заказчик]', 'Адрес филиала банка',\n",
    "              'Адрес филиала банка [Исполнитель]', 'Адрес филиала банка [Заказчик]'],\n",
    "     'ИНН/КПП': ['ИНН/КПП', 'ИНН КПП', 'ИНН КПП [Заказчик]', 'ИНН КПП [Исполнит]', 'ИНН/КПП [Заказчик]',\n",
    "                 'ИНН/КПП [Исполнит]', ''],\n",
    "     'банк': ['банк', 'Банк', 'Банк [Заказчик]', 'Банк [Исполнит]', 'Филиал банка [Заказчик]', \n",
    "              'Филиал банка [Исполнит]', ''],\n",
    "      \n",
    "     'к/с':['Корреспондентский счет', 'кс','к.с.', 'к/с', 'кор.счет', 'к/счет', 'кор.','кор/счет', 'корр.сч', 'корр./счет', 'корр/сч', 'корр. счет', 'кор/сч', ''], \n",
    "     'р/с': ['Расчетный счет', 'рс', 'р/с', 'р.с.','счет номер', 'счет', 'счет №', 'рас. счет',\n",
    "             'р. счет', 'рс.сч.', 'р.сч.', 'р/счет', 'рас/сч', 'рас/счет', 'рас', 'р/сч', ''],\n",
    "     'Грузоотправить':['Грузоотправить', 'Грузоотправить и его адрес', 'Грузоотправить и адрес', ''],\n",
    "     'Грузополучатель': ['Грузополучатель', 'Грузополучатель и его адрес', 'Грузополучатель и адрес', '']}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# список вариантов написания отдельных тегов для генерации случайного шаблона\n",
    "tegs = dict(\n",
    "org = ['Исполнитель [ORG]'],\n",
    "innkpp = ['ИНН/КПП [INN]/[KPP]', 'ИНН/КПП [INN]', 'ИНН/КПП [INN]/', 'ИНН КПП [INN] [KPP]', 'ИНН [INN]', 'ИНН [INN] КПП [KPP]',\n",
    "         'Исполнитель ИНН/КПП [INN]/[KPP]', 'Исполнитель ИНН КПП [INN] [KPP]', 'Исполнитель ИНН [INN]', \n",
    "          'Исполнитель ИНН [INN] КПП [KPP]', 'Исполнитель ИНН [INN]/КПП [KPP]',\n",
    "          'КПП/ИНН [KPP]/[INN]', 'КПП [KPP] ИНН [INN]', 'КПП [KPP]', 'Исполнитель КПП/ИНН [KPP]/[INN]', \n",
    "          'Исполнитель КПП ИНН [KPP] [INN]', 'Исполнитель КПП [KPP]', \n",
    "          'Исполнитель КПП [KPP] ИНН [INN]', 'Исполнитель КПП [KPP]/ИНН [INN]'],\n",
    "\n",
    "addr = ['адрес [LOC]'], \n",
    "bank = ['банк [BANK]'],\n",
    "rs = ['р/с [RS]'],\n",
    "ks = ['к/с [KS]'],\n",
    "tel = ['тел. [TEL]','[TEL]'],\n",
    "bik = ['БИК [BIK]'])\n",
    "\n",
    "# список шаблонов для генерации шаблонов текстов\n",
    "pat_dict = dict(org_set=['org', 'innkpp', 'addr', 'tel'], bank_set=['bank', 'bik', 'addr', 'rs', 'ks', 'tel'])\n",
    "pattern = [['org_set', 'bank_set'],\n",
    "           '[ORG] [PER]',\n",
    "           '[PER] [ORG]',\n",
    "           '[PER] [PER]',\n",
    "           '[ORG] [ORG]',\n",
    "           '[ORG] именуемое в дальнейшем \"Заказчик\", в лице генерального директора [PER]',\n",
    "           '[ORG] именуемое в дальнейшем \"Подрядчик\" с одной стороны',\n",
    "           '[ORG] именуемое в дальнейшем \"Заказчик\", в лице директора [PER]',\n",
    "           '[ORG] представитель Подрядчика генеральный директор [PER]',\n",
    "           '[ORG] именуемое в дальнейшем \"Заказчик\", в лице главного бухгалтера [PER]',\n",
    "           '[ORG] именуемое в дальнейшем \"Заказчик\", в лице заместителя главного бухгалтера [PER]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вспомогательные процедуры обработки шаблона и получения сущностей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подгружаем источники данных:компании, банки и фио\n",
    "\n",
    "Инициализируем модуль, который извлекает случайным образом сушности из источников"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akhmadiev/.local/lib/python3.7/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    }
   ],
   "source": [
    "comp_list_excel = '../data/interim/ner_tag_companies_and_banks.xlsx'\n",
    "tag_generator = GenerateTagValue(comp_list_excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подгружаем словари для использования при генерации шумов\n",
    "ru_dictionary_f = r'../data/external/russian_words_1.5M.txt'\n",
    "with open(ru_dictionary_f, 'r', encoding='cp1251') as f:\n",
    "    dictionary = [l.strip('\\n') for l in f.readlines()]\n",
    "\n",
    "eng_dictionary_f = r'../data/external/english_words.txt'\n",
    "with open(eng_dictionary_f, 'r', encoding='utf-8') as f:\n",
    "    eng_dictionary = [l.strip('\\n') for l in f.readlines()]\n",
    "dictionary.extend(eng_dictionary)    \n",
    "\n",
    "\n",
    "\n",
    "def get_random_date(start_y, end_y):\n",
    "    \"\"\"\n",
    "    генерация даты с выбором случайного шаблона написания\n",
    "    дата добавляется в качестве шума при обучении\n",
    "    \"\"\"\n",
    "    dt = datetime.datetime.strptime('{} {}'.format(random.randint(1, 366), random.randint(start_y, end_y)), '%j %Y')\n",
    "\n",
    "    seps = ['-', '.', '/', ' ']\n",
    "\n",
    "    sep = random.choice(seps)\n",
    "\n",
    "    formats = [f\"%m{sep}%d{sep}%Y\", f\"%Y{sep}%d{sep}%Y\", f\"%d{sep}%m{sep}%Y\", f\"%d %b %Y\", \n",
    "               f\"%d %B %Y\", f\"%d{sep}%b{sep}%Y\", f\"%d %B %Y\"]\n",
    "    frm = random.choice(formats)\n",
    "\n",
    "    return dt.strftime(frm)\n",
    "\n",
    "\n",
    "def get_noize():\n",
    "    \"\"\"\n",
    "    Генерация случайной последовательности случайных буквосочетаний\n",
    "    \"\"\"\n",
    "    n = []\n",
    "    for i in range(random.randint(1,4)):\n",
    "        rnd = random.randint(1,5)\n",
    "        if rnd == 1:\n",
    "            # собираем случайную последовательность символов\n",
    "            n.append(''.join([random.choice(characters) for i in range(random.randint(1,10))]))\n",
    "        elif rnd == 2:\n",
    "            # берем слово из словаря\n",
    "            n.append(random.choice(dictionary))\n",
    "        elif rnd == 3:\n",
    "            # собираем случайную последовательность цифр и символов ./\\- \n",
    "            n.append(''.join([random.choice(string.digits + './-\\ ') for i in range(random.randint(1,10))]))\n",
    "        else:\n",
    "            n.append(get_random_date(start_y=1990, end_y=2030))\n",
    "    return n\n",
    "\n",
    "def add_noize(tok_patt, dictionary):\n",
    "    \"\"\"\n",
    "    Добавляем шум между токенами шаблона\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for p in tok_patt:\n",
    "        result.extend([p])\n",
    "        # добавление шума в одном из 3х случаев\n",
    "        if random.randint(1,3) == 1:\n",
    "            result.extend(get_noize())\n",
    "    return result\n",
    "\n",
    "\n",
    "    \n",
    "def get_pattern_tags(l_pattern):\n",
    "    \"\"\"\n",
    "    Процедура возвращает словать, в котором ключами являются наименования тэгов внутри шаблона строки,\n",
    "    а значениями является число встреч тэка в строке\n",
    "    \"\"\"  \n",
    "    return dict(Counter(re.findall(r\"(\\[[A-Z]+\\])\", l_pattern)))\n",
    "    \n",
    "\n",
    "def fill_tags_by_values(tags, tag_generator):\n",
    "    \"\"\"\n",
    "    Заполняем найденные тэги \n",
    "    \"\"\"\n",
    "    tags_values={}\n",
    "    for key, value in tags.items():\n",
    "        values = []\n",
    "        for i in range(value):\n",
    "            try:\n",
    "                v = tag_generator.get_tag_value(key)\n",
    "                if v is None or v == 'non':\n",
    "                    v = \"\"\n",
    "            except:\n",
    "                v = \"\"\n",
    "            values.append(v)\n",
    "        tags_values[key] = values\n",
    "    return tags_values\n",
    "\n",
    "\n",
    "def tokenize_pattern(l_patt):\n",
    "    \"\"\"\n",
    "    Разбиение шаблона на токены, где отдельный токен - это либо тэг, либо ключевик\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    for i in l_patt.split():\n",
    "        \n",
    "        # разбиваем по пробелам\n",
    "        if i[0] == '[':\n",
    "            \n",
    "            # если наталкиваемся на тэг, то разбиение делаем по разделителю\n",
    "            s = i.split('/')\n",
    "            if len(s) > 1:\n",
    "                for j in range(len(s)-1):\n",
    "                    tokens.append(s[j])\n",
    "                    tokens.append(\"/\")\n",
    "                tokens.append(s[-1])\n",
    "            else:\n",
    "                tokens.append(s[0])\n",
    "        else:\n",
    "            tokens.append(i)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def make_bio_token(p_tokens, bio_tag):\n",
    "    \"\"\"\n",
    "    Размечаем по BIO-разметке интересующий тэг\n",
    "    \"\"\"\n",
    "    bio_patt = \"ru:{0}\\t{1}\\n\"\n",
    "    res = \"\"\n",
    "    if len(p_tokens) == 0:\n",
    "        return \"\"\n",
    "    l_tokens = p_tokens\n",
    "    if bio_tag == 'PER':\n",
    "        if random.randint(1,3) == 1:\n",
    "            ll = [l_tokens[0]]\n",
    "            for l in l_tokens[1:]:\n",
    "                ll.append(l[0]+'.')\n",
    "            l_tokens = ll\n",
    "    # если тэг значимый для нас, то раскидываем по началу и вхождениям тэга\n",
    "\n",
    "    try:\n",
    "        if bio_tag != \"O\":\n",
    "            res = bio_patt.format(l_tokens[0],\"B-\"+bio_tag)\n",
    "            for t in l_tokens[1:]:\n",
    "                res += bio_patt.format(t,\"I-\"+bio_tag)\n",
    "        else:\n",
    "            for t in l_tokens:\n",
    "                res += bio_patt.format(t, bio_tag)\n",
    "    except:\n",
    "        print(l_tokens)\n",
    "        return \"\"\n",
    "    return res\n",
    "\n",
    "def ip_tag_correction(l_tokens):\n",
    "    \"\"\"\n",
    "    Изменение тэгов с ORG на ORG + PER для ИП\n",
    "    \"\"\"\n",
    "    res = \"\"\n",
    "    if len(l_tokens) == 0:\n",
    "       return res\n",
    "    if l_tokens[0].lower() == 'ип':\n",
    "#         res += make_bio_token(l_tokens[:1], 'ORG')\n",
    "        res += make_bio_token(l_tokens[:1], 'O')\n",
    "        res += make_bio_token(l_tokens[1:], 'PER')\n",
    "    if l_tokens[0].lower() == 'индивидуальный':\n",
    "        res += make_bio_token(l_tokens[:2], 'ORG') # маркируем ИП как ORG\n",
    "#         res += make_bio_token(l_tokens[:2], 'O')\n",
    "        res += make_bio_token(l_tokens[2:], 'PER')\n",
    "    if l_tokens[-1].lower() == 'ип':\n",
    "        res += make_bio_token(l_tokens[-1:], 'ORG') # маркируем ИП как ORG\n",
    "#         res += make_bio_token(l_tokens[-1:], 'O')\n",
    "        res += make_bio_token(l_tokens[:-1], 'PER')\n",
    "    if l_tokens[-1].lower() == 'предприниматель':\n",
    "        res += make_bio_token(l_tokens[:2], 'ORG') # маркируем ИП как ORG\n",
    "#         res += make_bio_token(l_tokens[-2:], 'O')\n",
    "        res += make_bio_token(l_tokens[:-2], 'PER')\n",
    "    return res\n",
    "\n",
    "def get_bio_string(l_pattern, tag_gen, k_wrds, dictionary=None):\n",
    "    \"\"\"\n",
    "    формируем строку с BIO-разметкой\n",
    "    \"\"\"\n",
    "    tags_dict = {'[ORG]': 'ORG',\n",
    "            '[BANK]': 'ORG',\n",
    "            '[INN]': 'INNKPP',\n",
    "            '[KPP]': 'INNKPP',\n",
    "            '[RS]': 'RSKS',\n",
    "            '[KS]': 'RSKS',\n",
    "            '[LOC]': 'LOC',\n",
    "            '[PER]': 'PER',\n",
    "            '[BIK]': 'STAT',\n",
    "            '[TEL]': 'STAT',\n",
    "            '[OKPO]': 'STAT',\n",
    "            '[OKATO]': 'STAT',\n",
    "            '[OKTMO]': 'STAT'        \n",
    "            }\n",
    "    \n",
    "    l_patt = l_pattern\n",
    "    \n",
    "    # извлекаем тэги и их количество из шаблона\n",
    "    tags = get_pattern_tags(l_patt)\n",
    "      \n",
    "    # получаем значения для каждого тэга\n",
    "    entities = fill_tags_by_values(tags, tag_gen)\n",
    "\n",
    "    # токенизируем шаблон\n",
    "    tok_patt = tokenize_pattern(l_patt)\n",
    "    \n",
    "    if random.randint(1,5) >= 4:\n",
    "        if dictionary:\n",
    "            tok_patt = add_noize(tok_patt, dictionary)\n",
    "\n",
    "    # инициализируем токенизатор\n",
    "    toktok = ToktokTokenizer()   \n",
    "    \n",
    "    # производим BIO-разметку\n",
    "    result = \"\"\n",
    "    for i,tt in enumerate(tok_patt):\n",
    "        t = tt\n",
    "        # случайным образом затираем сущность - разбавляем насыщенность тегами\n",
    "        if random.randint(1,5) == 1:\n",
    "            t = ''\n",
    "        \n",
    "        #если есть сгенерированная сущность, то начинаем разметку\n",
    "        if entities.get(t):\n",
    "            \n",
    "            # токенизируем первую по списку сущность\n",
    "            tokens = toktok.tokenize(entities[t][0])\n",
    "            \n",
    "            # исключаем использованную сущность из множества сгенерированных\n",
    "            entities[t] = entities[t][1:]\n",
    "            tok_patt[i] = tokens\n",
    "            \n",
    "            # выбираем верный BIO-тэг\n",
    "            ner_tag = tags_dict.get(t)\n",
    "            \n",
    "            # проверка, если сущность является ИП, то надо изменить BIO-тэги для него\n",
    "            r = ip_tag_correction(tokens)\n",
    "            # если проверка по ИП дала пустую строку, то делаем стандартную разметку\n",
    "            # если выдала не пустуюс строку, то она и будет считаться верной для данного токена\n",
    "            if len(r) == 0:\n",
    "                # производим биоразметку\n",
    "                if ner_tag is None:\n",
    "                    ner_tag = 'O'\n",
    "                result += make_bio_token(tokens, ner_tag)\n",
    "            else:\n",
    "                result += r\n",
    "        else:\n",
    "            # если нет сгенерированной сущности, то ставим тэг \"O\"\n",
    "            \n",
    "            t = generate_key_synonims(t, k_wrds)\n",
    "            \n",
    "            \n",
    "            result += make_bio_token(t.split(), 'O')#f\"ru:{t}\\tO\\n\"\n",
    "    return result\n",
    "\n",
    "\n",
    "def generate_key_synonims(key_token, key_words):\n",
    "    \"\"\"\n",
    "    Заменяем ключевые слова на синонимы\n",
    "    \"\"\"\n",
    "    values = key_words.get(key_token)\n",
    "    if values is not None:\n",
    "        s = random.choice(values)\n",
    "        syn = replace_in_tag(s, key_words)\n",
    "    else:\n",
    "        syn = key_token\n",
    "    return syn\n",
    "\n",
    "def replace_in_tag(l_syn, kw):\n",
    "    \"\"\"\n",
    "    Заменяем ключевые слова на синонимы в случае. если в синониме есть тоже ключевик\n",
    "    \"\"\"\n",
    "    for p in re.findall(r\"(\\[[а-яё]+\\])\", l_syn, re.IGNORECASE):\n",
    "        for w in re.findall(r\"[а-яё]+\", p, re.IGNORECASE):\n",
    "            s = generate_key_synonims(w, kw)\n",
    "            l_syn = l_syn.replace(p, s)\n",
    "    return l_syn\n",
    "\n",
    "\n",
    "def get_random_patt(df):\n",
    "    \"\"\"\n",
    "    генерация случайного шаблона: либо по правилу, либо из списка\n",
    "    \"\"\"\n",
    "    \n",
    "    rnd = random.randint(1,4)\n",
    "    if rnd in [1,2]:\n",
    "        # генерируем по правилу\n",
    "        pp = make_random_pattern(pat_dict=pat_dict, tegs=tegs, patt=pattern[0])\n",
    "    elif rnd == 3:\n",
    "        # генерируем из заготовленного шорт-листа (увеличиваем плотность интересующих нас шаблонов)\n",
    "        pp = random.sample(pattern[1:], 1)[0]\n",
    "    else:\n",
    "        # извлекаем случайным образом из файла заготовленных шаблонов\n",
    "        pp = df.sample()['Шаблоны'].values[0]\n",
    "    return pp\n",
    "\n",
    "def make_random_pattern(pat_dict, tegs, patt):\n",
    "    \"\"\"\n",
    "    на основе правил генерирует случайноую строку шаблона\n",
    "    \"\"\"\n",
    "    pattern_str = []\n",
    "    rnd = random.randint(1,3)\n",
    "    if rnd > 1:\n",
    "        pp = patt\n",
    "    else:\n",
    "        pp = random.sample(patt, len(patt))\n",
    "    for key in pp:\n",
    "        for k in random.sample(pat_dict[key], len(pat_dict[key])):\n",
    "            s = random.sample(tegs[k],1)[0]\n",
    "            pattern_str.append(s)\n",
    "    return ' '.join(pattern_str).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверяем как работает генерация BIO-строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подгружаем список шаблонов\n",
    "\n",
    "df_patterns = pd.read_excel(\"../data/interim/patterns.xlsx\", sheet_name='Шаблоны строк', engine='openpyxl').dropna(subset=['Шаблоны'])\n",
    "df_patterns = df_patterns[['Шаблоны']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_patt = random.choice(df_patterns.values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_patt = '[ORG] именуемое в дальнейшем \"Заказчик\", в лице генерального директора [PER]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ru:Покупатель\tO\n",
      "ru:ФИЛИАЛ\tB-ORG\n",
      "ru:АКЦИОНЕРНОГО\tI-ORG\n",
      "ru:ОБЩЕСТВА\tI-ORG\n",
      "ru:\"\tI-ORG\n",
      "ru:МОСКОВСКАЯ\tI-ORG\n",
      "ru:ОБЛАСТНАЯ\tI-ORG\n",
      "ru:ЭНЕРГОСЕТЕВАЯ\tI-ORG\n",
      "ru:КОМПАНИЯ\tI-ORG\n",
      "ru:\"\tI-ORG\n",
      "ru:КРАСНОЗНАМЕНСКИЕ\tI-ORG\n",
      "ru:ЭЛЕКТРИЧЕСКИЕ\tI-ORG\n",
      "ru:СЕТИ\tI-ORG\n",
      "ru:ИНН\tO\n",
      "ru:КПП\tO\n",
      "ru:Подрядчик\tO\n",
      "ru:5920998773\tB-INNKPP\n",
      "ru:575101001\tB-INNKPP\n",
      "ru:127591\tB-LOC\n",
      "ru:,\tI-LOC\n",
      "ru:г\tI-LOC\n",
      "ru:Москва\tI-LOC\n",
      "ru:,\tI-LOC\n",
      "ru:р-н\tI-LOC\n",
      "ru:Восточное\tI-LOC\n",
      "ru:Дегунино\tI-LOC\n",
      "ru:,\tI-LOC\n",
      "ru:ул\tI-LOC\n",
      "ru:Дубнинская\tI-LOC\n",
      "ru:,\tI-LOC\n",
      "ru:д\tI-LOC\n",
      "ru:85\tI-LOC\n",
      "ru:стр\tI-LOC\n",
      "ru:17\tI-LOC\n",
      "ru:Филиал\tO\n",
      "ru:банка\tO\n",
      "ru:Заказчик\tO\n",
      "ru:ПУБЛИЧНОЕ\tB-ORG\n",
      "ru:АКЦИОНЕРНОЕ\tI-ORG\n",
      "ru:ОБЩЕСТВО\tI-ORG\n",
      "ru:\"\tI-ORG\n",
      "ru:БАНК\tI-ORG\n",
      "ru:\"\tI-ORG\n",
      "ru:САНКТ-ПЕТЕРБУРГ\tI-ORG\n",
      "ru:\"\tI-ORG\n",
      "ru:БИК\tO\n",
      "ru:046220928\tB-STAT\n",
      "ru:кор/счет\tO\n",
      "ru:30419663522686801079\tB-RSKS\n",
      "ru:тел.\tO\n",
      "ru:7\tB-STAT\n",
      "ru:361\tI-STAT\n",
      "ru:031\tI-STAT\n",
      "ru:3026\tI-STAT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_bio_string(l_patt, tag_generator, kw, dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ORG] представитель Подрядчика генеральный директор [PER]'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получаем случайный шаблон\n",
    "get_random_patt(df_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Процедуры генерации обучающего файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_generator(df, limit=100, random=True, rule=True):\n",
    "    \"\"\"\n",
    "    Выбор шаблона из списка в dataframe\n",
    "    Варианты генерации: случайный выбор шаблона и пробегаться последвательно по всему объему\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    if rule:\n",
    "        while i<limit:\n",
    "            yield get_random_patt(df)\n",
    "            i+=1\n",
    "    \n",
    "    if random:\n",
    "        while i<limit:\n",
    "            yield df.sample()['Шаблоны'].values[0]\n",
    "            i+=1\n",
    "    else:\n",
    "        j = 0\n",
    "        while i<limit:\n",
    "            if i >= df.shape[0]:\n",
    "                j = 0\n",
    "            yield df[df.index == j]['Шаблоны'].values[0]\n",
    "            j+=1\n",
    "            i+=1\n",
    "\n",
    "def make_bio_file(f_lname, l_df_patterns, l_tag_generator, kw, limit=1000, random=True, append=False):\n",
    "    \"\"\"\n",
    "    Создание файла со строками в BIO-разметке\n",
    "    \"\"\"\n",
    "    \n",
    "    if not append:\n",
    "        assert not os.path.exists(f_lname), \"Файл существует, для дозаписи передайте в append True\"\n",
    "    with open(f_lname, 'a', encoding='utf-8') as the_file:\n",
    "        for p in sample_generator(l_df_patterns, limit=limit, random=random):\n",
    "            patt = p\n",
    "            if patt is not None and patt != 'nan':\n",
    "                line = get_bio_string(patt, l_tag_generator, kw)\n",
    "                the_file.write(line)\n",
    "                the_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание файлов с BIO-разметкой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>Для обучения по пайпу от huggingface необходимо создать 4 файла\n",
    "\n",
    "При создании каждого из файлов используем соответствующие файлы с шаблонами и данными (исключаем пересечения обучения с тестами)\n",
    "\n",
    "\n",
    "После генерации 4х файлов их надо упаковат в фрхив default.tar.xz - под этот файл настроен обработчик, который преобразовывает файлы в формат datasets от huggighface</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"../data/interim/patterns.xlsx\"\n",
    "df_patterns = pd.read_excel(\"../data/processed/test1_patterns.xlsx\", sheet_name='Шаблоны строк', engine='openpyxl').dropna(subset=['Шаблоны'])\n",
    "df_patterns = df_patterns[['Шаблоны']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# необходимо создать 4 файла: train/test/dev/extra\n",
    "# для каждого файла есть непересекающиеся шаблоны и примеры организаций\n",
    "# \n",
    "df_patterns = pd.read_excel(\"../data/processed/train_patterns.xlsx\", sheet_name='Шаблоны строк', engine='openpyxl').dropna(subset=['Шаблоны'])\n",
    "df_patterns = df_patterns[['Шаблоны']]\n",
    "comp_list_excel = '../data/processed/train_ner_tag_companies_and_banks.xlsx'\n",
    "tag_generator = GenerateTagValue(comp_list_excel)\n",
    "\n",
    "f_name = \"../data/processed/train\"\n",
    "make_bio_file(f_name, df_patterns, tag_generator, kw, limit=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timekeeper/.local/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "df_patterns = pd.read_excel(\"../data/processed/test1_patterns.xlsx\", sheet_name='Шаблоны строк', engine='openpyxl').dropna(subset=['Шаблоны'])\n",
    "df_patterns = df_patterns[['Шаблоны']]\n",
    "comp_list_excel = '../data/processed/test1_ner_tag_companies_and_banks.xlsx'\n",
    "tag_generator = GenerateTagValue(comp_list_excel)\n",
    "\n",
    "f_name = \"../data/processed/test\"\n",
    "make_bio_file(f_name, df_patterns, tag_generator, kw, limit=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_patterns = pd.read_excel(\"../data/processed/test1_patterns.xlsx\", sheet_name='Шаблоны строк', engine='openpyxl').dropna(subset=['Шаблоны'])\n",
    "# df_patterns = df_patterns[['Шаблоны']]\n",
    "# comp_list_excel = '../data/processed/test1_ner_tag_companies_and_banks.xlsx'\n",
    "# tag_generator = GenerateTagValue(comp_list_excel)\n",
    "\n",
    "f_name = \"../data/processed/dev\"\n",
    "make_bio_file(f_name, df_patterns, tag_generator, kw, limit=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_patterns = pd.read_excel(\"../data/processed/test1_patterns.xlsx\", sheet_name='Шаблоны строк', engine='openpyxl').dropna(subset=['Шаблоны'])\n",
    "# df_patterns = df_patterns[['Шаблоны']]\n",
    "# comp_list_excel = '../data/processed/test1_ner_tag_companies_and_banks.xlsx'\n",
    "# tag_generator = GenerateTagValue(comp_list_excel)\n",
    "\n",
    "f_name = \"../data/processed/extra\"\n",
    "make_bio_file(f_name, df_patterns, tag_generator, kw, limit=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
