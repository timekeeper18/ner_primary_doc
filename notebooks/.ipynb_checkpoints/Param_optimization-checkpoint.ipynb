{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46533a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_dataset, load_metric\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer,  DataCollatorForTokenClassification, EarlyStoppingCallback\n",
    "import transformers\n",
    "\n",
    "\n",
    "#local directories\n",
    "\n",
    "from pathlib import Path\n",
    "BASE_DIR = Path().cwd().parent\n",
    "wikiann_dl_dir = BASE_DIR.joinpath(\"data/interim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c978e8",
   "metadata": {},
   "source": [
    "## Задаем параметр модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1573dae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"ner\" # Should be one of \"ner\", \"pos\" or \"chunk\"\n",
    "model_checkpoint = \"DeepPavlov/rubert-base-cased\"#\"bert-base-multilingual-uncased\"#\"mrm8488/distilbert-base-multi-cased-finetuned-typo-detection\" \"distilbert-base-uncased\" \n",
    "batch_size = 32\n",
    "# batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7192607e",
   "metadata": {},
   "source": [
    "## Подгружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2e9f244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c7de00f0f2af4a11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/ewp/DEV/ld_ner_bert_learn/data/interim/cache/wikiann/default-c7de00f0f2af4a11/1.1.0/5695de592d40d13b53e20479dbfaa3948fc461d991d92cb4ae429105e4d5d170...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d86b87fc2664355bcf8b3a9e94c5814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181d2c8aae77482f9ae9802264736d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ecb604f9f454df6b8f4198f876cd474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Dataset wikiann downloaded and prepared to /home/ewp/DEV/ld_ner_bert_learn/data/interim/cache/wikiann/default-c7de00f0f2af4a11/1.1.0/5695de592d40d13b53e20479dbfaa3948fc461d991d92cb4ae429105e4d5d170. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "shutil.rmtree(str(wikiann_dl_dir.joinpath('cache')))\n",
    "\n",
    "os.mkdir(str(wikiann_dl_dir.joinpath('cache')))\n",
    "\n",
    "datasets = load_dataset(str(wikiann_dl_dir.joinpath(\"wikiann_local.py\")), data_files=str(wikiann_dl_dir.joinpath(\"default.zip\")), \n",
    "                        cache_dir=str(wikiann_dl_dir.joinpath('cache')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2db6b6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-PER',\n",
       " 'I-PER',\n",
       " 'B-ORG',\n",
       " 'I-ORG',\n",
       " 'B-LOC',\n",
       " 'I-LOC',\n",
       " 'B-INNKPP',\n",
       " 'I-INNKPP',\n",
       " 'B-RSKS',\n",
       " 'I-RSKS',\n",
       " 'B-STAT',\n",
       " 'I-STAT']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = datasets[\"train\"].features[f\"{task}_tags\"].feature.names\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f73beb3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>langs</th>\n",
       "      <th>ner_tags</th>\n",
       "      <th>spans</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru]</td>\n",
       "      <td>[B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, O, O, O, O, O, O]</td>\n",
       "      <td>[ORG: АО 79 ЦЕНТРАЛЬНАЯ ИНЖЕНЕРНАЯ БАЗА Филиал]</td>\n",
       "      <td>[АО, 79, ЦЕНТРАЛЬНАЯ, ИНЖЕНЕРНАЯ, БАЗА, Филиал, именуемое, дальнейшем, \"Подрядчик\", с, одной, стороны]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru]</td>\n",
       "      <td>[O, B-ORG, I-ORG, I-ORG, I-ORG, O, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, O, O, B-INNKPP, O, O, O]</td>\n",
       "      <td>[ORG: \" МИА-ФАРМ \" ООО, ORG: Коммерческий Банк \" Кутузовский \" Общество с ограниченной ответственностью, INNKPP: 8613007049]</td>\n",
       "      <td>[Исполнитель, \", МИА-ФАРМ, \", ООО, рс, Коммерческий, Банк, \", Кутузовский, \", Общество, с, ограниченной, ответственностью, ИНН, КПП, 8613007049, /, тел., к/счет]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru]</td>\n",
       "      <td>[O, B-ORG, I-ORG, B-PER, I-PER, I-PER, O, B-INNKPP, O, O, O, O, B-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, O, O, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, O, B-STAT, I-STAT, I-STAT, I-STAT, I-STAT, I-STAT]</td>\n",
       "      <td>[ORG: Индивидуальный предприниматель, PER: Ысакова Бурулкан Нурдиновна, INNKPP: 7704845575, LOC: 654222 , Кемеровская область - Кузбасс , Новокузнецкий р-н , поселок Чистая Грива, ORG: Акционерный коммерческий банк \" Инвестбанк \" ( открытое акционерное общество ), STAT: 8 ( 843 ) 723 1911]</td>\n",
       "      <td>[Заказчик, Индивидуальный, предприниматель, Ысакова, Бурулкан, Нурдиновна, ИНН, 7704845575, Адрес, филиала, банка, Клиент, 654222, ,, Кемеровская, область, -, Кузбасс, ,, Новокузнецкий, р-н, ,, поселок, Чистая, Грива, Филиал, банка, Акционерный, коммерческий, банк, \", Инвестбанк, \", (, открытое, акционерное, общество, ), корр.сч, 8, (, 843, ), 723, 1911]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru]</td>\n",
       "      <td>[O, B-ORG, I-ORG, B-PER, I-PER, I-PER, O, O, O, O, B-INNKPP, O, O, O, B-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, O, O, B-STAT, O]</td>\n",
       "      <td>[ORG: Индивидуальный предприниматель, PER: Чужинина Вера Николаевна, INNKPP: 431201001, LOC: 654000 , Кемеровская область - Кузбасс , г Новокузнецк, STAT: 041161321]</td>\n",
       "      <td>[Лицензиат, Индивидуальный, предприниматель, Чужинина, Вера, Николаевна, ИНН, КПП, Поставщик, /, 431201001, Адрес, филиала, банка, 654000, ,, Кемеровская, область, -, Кузбасс, ,, г, Новокузнецк, БИК, Банка, 041161321, тел.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru]</td>\n",
       "      <td>[O, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, O, O, O, B-INNKPP, O, O, B-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, O, O, B-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, O, O, O, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, O, O, B-STAT, O, B-RSKS, O, B-RSKS]</td>\n",
       "      <td>[ORG: ВОЛГОГРАДСКИЙ ФИЛИАЛ АКЦИОНЕРНОГО ОБЩЕСТВА \" СТРАХОВОЕ ОБЩЕСТВО ГАЗОВОЙ ПРОМЫШЛЕННОСТИ \", INNKPP: 7802553644, LOC: ОБЛАСТЬ РОСТОВСКАЯ ГОРОД РОСТОВ-НА-ДОНУ УЛИЦА БОЛЬШАЯ САДОВАЯ 188А, LOC: ОБЛАСТЬ НОВОСИБИРСКАЯ ГОРОД НОВОСИБИРСК УЛИЦА ДОБРОЛЮБОВА ДОМ 160, ORG: АКЦИОНЕРНОЕ ОБЩЕСТВО \" ВЛАДБИЗНЕСБАНК \", STAT: 049090650, RSKS: 40712478033062647294, RSKS: 30200193850590030083]</td>\n",
       "      <td>[Подрядчик, ВОЛГОГРАДСКИЙ, ФИЛИАЛ, АКЦИОНЕРНОГО, ОБЩЕСТВА, \", СТРАХОВОЕ, ОБЩЕСТВО, ГАЗОВОЙ, ПРОМЫШЛЕННОСТИ, \", тел., ИНН, Субподрядчик, 7802553644, Адрес, банка, ОБЛАСТЬ, РОСТОВСКАЯ, ГОРОД, РОСТОВ-НА-ДОНУ, УЛИЦА, БОЛЬШАЯ, САДОВАЯ, 188А, Адрес, Исполнитель, ОБЛАСТЬ, НОВОСИБИРСКАЯ, ГОРОД, НОВОСИБИРСК, УЛИЦА, ДОБРОЛЮБОВА, ДОМ, 160, тел., Филиал, банка, АКЦИОНЕРНОЕ, ОБЩЕСТВО, \", ВЛАДБИЗНЕСБАНК, \", БИК, Банка, 049090650, рс.сч., 40712478033062647294, кор/счет, 30200193850590030083]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru]</td>\n",
       "      <td>[O, O, O, O, B-LOC, I-LOC, I-LOC, I-LOC, I-LOC, B-ORG, I-ORG, I-ORG, I-ORG, O, O, B-INNKPP, B-INNKPP, B-STAT, I-STAT, I-STAT, I-STAT, I-STAT, I-STAT, O, O, O, O, B-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, O, O, O, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, O, O, B-STAT, O, O, B-RSKS, O, B-RSKS]</td>\n",
       "      <td>[LOC: Кемеровская область , город Таштагол, ORG: ООО \" АВЗ \", INNKPP: 4421004745, INNKPP: 781601001, STAT: 8 ( 376 ) 483 3859, LOC: 664000 , Иркутская обл , г Иркутск, ORG: АКЦИОНЕРНОЕ ОБЩЕСТВО КОММЕРЧЕСКИЙ БАНК \" КОСМОС \", STAT: 041284610, RSKS: 42154462433419730368, RSKS: 30245827149162134913]</td>\n",
       "      <td>[Адрес, филиала, банка, Заказчик, Кемеровская, область, ,, город, Таштагол, ООО, \", АВЗ, \", КПП, Исп-тель, 4421004745, 781601001, 8, (, 376, ), 483, 3859, Адрес, филиала, банка, Плательщик, 664000, ,, Иркутская, обл, ,, г, Иркутск, Филиал, банка, Подрядчик, АКЦИОНЕРНОЕ, ОБЩЕСТВО, КОММЕРЧЕСКИЙ, БАНК, \", КОСМОС, \", БИК, Банка, 041284610, р., счет, 42154462433419730368, к/с, 30245827149162134913]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[ru, ru, ru, ru, ru, ru, ru, ru]</td>\n",
       "      <td>[B-ORG, I-ORG, O, O, O, O, O, O]</td>\n",
       "      <td>[ORG: ООО БИПЭК]</td>\n",
       "      <td>[ООО, БИПЭК, именуемое, в, \"Подрядчик\", с, одной, стороны]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru]</td>\n",
       "      <td>[O, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, B-INNKPP, O, O, B-INNKPP, B-STAT, O, O, O, B-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, O, O, B-STAT, I-STAT, I-STAT, I-STAT, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG]</td>\n",
       "      <td>[ORG: \" СИРИУС-ТРЕЙД \" Общество с ограниченной ответственностью, INNKPP: 7713469944, INNKPP: 583701001, STAT: 045270361, LOC: ОБЛАСТЬ МОСКОВСКАЯ ГОРОД ХИМКИ УЛИЦА ПРОЛЕТАРСКАЯ ДОМ 18, STAT: 8 924 970 0415, ORG: ФИЛИАЛ АКБ \" ЛЕГИОН \" ( АО ) В Г. САНКТ-ПЕТЕРБУРГ]</td>\n",
       "      <td>[Лицензиат, \", СИРИУС-ТРЕЙД, \", Общество, с, ограниченной, ответственностью, 7713469944, КПП, Субподрядчик, 583701001, 045270361, Адрес, банка, Инвестор, ОБЛАСТЬ, МОСКОВСКАЯ, ГОРОД, ХИМКИ, УЛИЦА, ПРОЛЕТАРСКАЯ, ДОМ, 18, кор/сч, тел., 8, 924, 970, 0415, ФИЛИАЛ, АКБ, \", ЛЕГИОН, \", (, АО, ), В, Г., САНКТ-ПЕТЕРБУРГ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru, ru]</td>\n",
       "      <td>[O, O, O, B-INNKPP, O, O, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, B-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, O, B-STAT, I-STAT, I-STAT, I-STAT, I-STAT, B-STAT, O, O, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, B-STAT, I-STAT, I-STAT, I-STAT, O, O, B-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC, O, B-RSKS, O, B-RSKS]</td>\n",
       "      <td>[INNKPP: 7725806898, ORG: \" ЛЕСАД \" Общество с ограниченной ответственностью, LOC: 115184 , г Москва , р-н Замоскворечье , ул Малая Ордынка , д 40, STAT: +7 883 63 50 706, STAT: 041404917, ORG: Общество с ограниченной ответственностью коммерческий банк \" Развитие \", STAT: 8-( 965 ) -07-69-236, LOC: ОБЛАСТЬ КАЛИНИНГРАДСКАЯ ГОРОД КАЛИНИНГРАД УЛИЦА ФРУНЗЕ ДОМ 56 КВАРТИРА 29, RSKS: 49671729894104168871, RSKS: 30079162936460455356]</td>\n",
       "      <td>[Исполнитель, ИНН, КПП, 7725806898, /, Клиент, \", ЛЕСАД, \", Общество, с, ограниченной, ответственностью, 115184, ,, г, Москва, ,, р-н, Замоскворечье, ,, ул, Малая, Ордынка, ,, д, 40, тел., +7, 883, 63, 50, 706, 041404917, Банк, Зак-чик, Общество, с, ограниченной, ответственностью, коммерческий, банк, \", Развитие, \", 8-(, 965, ), -07-69-236, Адрес, Субподрядчик, ОБЛАСТЬ, КАЛИНИНГРАДСКАЯ, ГОРОД, КАЛИНИНГРАД, УЛИЦА, ФРУНЗЕ, ДОМ, 56, КВАРТИРА, 29, р/с, 49671729894104168871, кс, 30079162936460455356]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[ru, ru, ru, ru, ru, ru, ru]</td>\n",
       "      <td>[O, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, O]</td>\n",
       "      <td>[ORG: Эрмекбаева Азиза Максутовна , ИП]</td>\n",
       "      <td>[Покупатель, Эрмекбаева, Азиза, Максутовна, ,, ИП, ИНН]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))\n",
    "    \n",
    "show_random_elements(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15d8cb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, do_lower_case=True)\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59155078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 26856, 128, 3998, 7635, 16541, 106, 106, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Привет, это одно предложение!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b678890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '\"', 'ва', '##б', '##ко', 'рус', '\"', 'о', '##оо', 'адрес', 'р', '.', 'сч', '.', '433', '##28', '##47', '##43', '##24', '##56', '##19', '##67', '##82', '##9', 'банк', 'исп', '-', 'тель', '/', '352', '##801', '##001', 'тел', '.', '+', '7', '(', '835', ')', '03', '74', '505', 'бик', '048', '##56', '##78', '##63', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "example = datasets[\"train\"][3]\n",
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a40a4744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 48\n"
     ]
    }
   ],
   "source": [
    "word_ids = tokenized_input.word_ids()\n",
    "aligned_labels = [-100 if i is None else example[f\"{task}_tags\"][i] for i in word_ids]\n",
    "print(len(aligned_labels), len(tokenized_input[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b2b410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_all_tokens = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93593083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"{task}_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a5a98b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc1ad150c07405bad9657a7fef177d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7be531eba447f7a452a5be37b5acc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef55d3005cf43b49750fb29c1c246f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a669220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f85ce4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef125339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'INNKPP': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'RSKS': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'STAT': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'overall_precision': 1.0,\n",
       " 'overall_recall': 1.0,\n",
       " 'overall_f1': 1.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "labels = [label_list[i] for i in example[f\"{task}_tags\"]]\n",
    "metric.compute(predictions=[labels], references=[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f4fb719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc2f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Замораживаем все параметры, кроме головы\n",
    "# for param in model.distilbert.parameters():\n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ce7a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    if param.requires_grad:\n",
    "        print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d83cd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разморозка - не запускаем\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9624770",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    f\"test-{task}\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-4, #2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.001, #0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945bebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разовый запуск обучения\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c078fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcce2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, labels, _ = trainer.predict(tokenized_datasets[\"test\"])\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Remove ignored index (special tokens)\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e162e821",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(BASE_DIR.joinpath('models/ner_dpbert_37epoch_86f1_93acc.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b9d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ba9b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f81da6c9",
   "metadata": {},
   "source": [
    "## Подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96eb5aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_tainer(lgrid, model, tokenized_datasets, compute_metrics, data_collator):\n",
    "    args = TrainingArguments(\n",
    "        f\"test-{task}\",\n",
    "        overwrite_output_dir=True,\n",
    "        evaluation_strategy = \"epoch\",\n",
    "        learning_rate=lgrid['learning_rate'],\n",
    "        per_device_train_batch_size=lgrid['batch_size'],\n",
    "        per_device_eval_batch_size=lgrid['batch_size'],\n",
    "        num_train_epochs=30,\n",
    "        weight_decay=lgrid['weight_decay'],\n",
    "        save_strategy=\"no\",\n",
    "        load_best_model_at_end = False,\n",
    "    )\n",
    "\n",
    "    # Замораживаем все параметры, кроме головы\n",
    "    # for param in model.distilbert.parameters():\n",
    "    for param in model.bert.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    return Trainer(\n",
    "                    model,\n",
    "                    args,\n",
    "                    train_dataset=tokenized_datasets[\"train\"],\n",
    "                    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "                    data_collator=data_collator,\n",
    "                    tokenizer=tokenizer,\n",
    "                    compute_metrics=compute_metrics,\n",
    "                    \n",
    "#                     callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "404a4151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer at 0x7f87b9698240>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверяем работоспособность процедуры\n",
    "i = {'learning_rate': 2e-05, 'batch_size': 16, 'weight_decay': 0.0}\n",
    "get_tainer(i, model, tokenized_datasets, compute_metrics, data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4221567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем сетку параметров\n",
    "grid = {'learning_rate': [5e-5, 2e-4, 2e-3],\n",
    "        'batch_size': [32],\n",
    "       'weight_decay':[0.0, 0.1, 0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97d47d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def process(d):\n",
    "    to_product = []  # [[('a', 1), ('a', 2)], [('b', 3),], ...]\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, list):\n",
    "            to_product.append([(k, i) for i in v])\n",
    "        elif isinstance(v, dict):\n",
    "            to_product.append([(k, i) for i in process(v)])\n",
    "        else:\n",
    "            to_product.append([(k, v)])\n",
    "    return [dict(l) for l in product(*to_product)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8289dfbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 5e-05, 'batch_size': 32, 'weight_decay': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4710' max='4710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4710/4710 22:02, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.561983</td>\n",
       "      <td>0.368171</td>\n",
       "      <td>0.484585</td>\n",
       "      <td>0.418432</td>\n",
       "      <td>0.611974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.118332</td>\n",
       "      <td>0.451447</td>\n",
       "      <td>0.534347</td>\n",
       "      <td>0.489411</td>\n",
       "      <td>0.701939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.919972</td>\n",
       "      <td>0.500901</td>\n",
       "      <td>0.567521</td>\n",
       "      <td>0.532134</td>\n",
       "      <td>0.739369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.485300</td>\n",
       "      <td>0.803444</td>\n",
       "      <td>0.546136</td>\n",
       "      <td>0.601129</td>\n",
       "      <td>0.572314</td>\n",
       "      <td>0.768072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.485300</td>\n",
       "      <td>0.725399</td>\n",
       "      <td>0.577852</td>\n",
       "      <td>0.634433</td>\n",
       "      <td>0.604823</td>\n",
       "      <td>0.788184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.485300</td>\n",
       "      <td>0.667748</td>\n",
       "      <td>0.603770</td>\n",
       "      <td>0.657881</td>\n",
       "      <td>0.629665</td>\n",
       "      <td>0.803365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.836000</td>\n",
       "      <td>0.623253</td>\n",
       "      <td>0.624749</td>\n",
       "      <td>0.675423</td>\n",
       "      <td>0.649099</td>\n",
       "      <td>0.814437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.836000</td>\n",
       "      <td>0.588452</td>\n",
       "      <td>0.637256</td>\n",
       "      <td>0.687451</td>\n",
       "      <td>0.661403</td>\n",
       "      <td>0.822237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.836000</td>\n",
       "      <td>0.559766</td>\n",
       "      <td>0.650601</td>\n",
       "      <td>0.699870</td>\n",
       "      <td>0.674337</td>\n",
       "      <td>0.829483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.676500</td>\n",
       "      <td>0.535807</td>\n",
       "      <td>0.661009</td>\n",
       "      <td>0.711984</td>\n",
       "      <td>0.685551</td>\n",
       "      <td>0.835251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.676500</td>\n",
       "      <td>0.515590</td>\n",
       "      <td>0.669737</td>\n",
       "      <td>0.719844</td>\n",
       "      <td>0.693887</td>\n",
       "      <td>0.839943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.676500</td>\n",
       "      <td>0.498595</td>\n",
       "      <td>0.676132</td>\n",
       "      <td>0.725836</td>\n",
       "      <td>0.700103</td>\n",
       "      <td>0.843678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.595700</td>\n",
       "      <td>0.483463</td>\n",
       "      <td>0.684528</td>\n",
       "      <td>0.733304</td>\n",
       "      <td>0.708077</td>\n",
       "      <td>0.848205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.595700</td>\n",
       "      <td>0.471347</td>\n",
       "      <td>0.688620</td>\n",
       "      <td>0.737299</td>\n",
       "      <td>0.712129</td>\n",
       "      <td>0.851089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.595700</td>\n",
       "      <td>0.459622</td>\n",
       "      <td>0.695781</td>\n",
       "      <td>0.744030</td>\n",
       "      <td>0.719097</td>\n",
       "      <td>0.854541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.547800</td>\n",
       "      <td>0.450082</td>\n",
       "      <td>0.699801</td>\n",
       "      <td>0.747112</td>\n",
       "      <td>0.722683</td>\n",
       "      <td>0.857066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.547800</td>\n",
       "      <td>0.440980</td>\n",
       "      <td>0.704863</td>\n",
       "      <td>0.750803</td>\n",
       "      <td>0.727108</td>\n",
       "      <td>0.859606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.547800</td>\n",
       "      <td>0.433784</td>\n",
       "      <td>0.707257</td>\n",
       "      <td>0.752801</td>\n",
       "      <td>0.729319</td>\n",
       "      <td>0.861115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.547800</td>\n",
       "      <td>0.426718</td>\n",
       "      <td>0.711452</td>\n",
       "      <td>0.758315</td>\n",
       "      <td>0.734136</td>\n",
       "      <td>0.863371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.516700</td>\n",
       "      <td>0.420553</td>\n",
       "      <td>0.715423</td>\n",
       "      <td>0.760964</td>\n",
       "      <td>0.737491</td>\n",
       "      <td>0.865374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.516700</td>\n",
       "      <td>0.415469</td>\n",
       "      <td>0.716786</td>\n",
       "      <td>0.762788</td>\n",
       "      <td>0.739072</td>\n",
       "      <td>0.866718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.516700</td>\n",
       "      <td>0.410937</td>\n",
       "      <td>0.718224</td>\n",
       "      <td>0.764785</td>\n",
       "      <td>0.740773</td>\n",
       "      <td>0.868003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.495400</td>\n",
       "      <td>0.407371</td>\n",
       "      <td>0.719757</td>\n",
       "      <td>0.765480</td>\n",
       "      <td>0.741914</td>\n",
       "      <td>0.868795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.495400</td>\n",
       "      <td>0.403903</td>\n",
       "      <td>0.721605</td>\n",
       "      <td>0.766913</td>\n",
       "      <td>0.743569</td>\n",
       "      <td>0.870065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.495400</td>\n",
       "      <td>0.400969</td>\n",
       "      <td>0.723111</td>\n",
       "      <td>0.768954</td>\n",
       "      <td>0.745328</td>\n",
       "      <td>0.871156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.483000</td>\n",
       "      <td>0.398871</td>\n",
       "      <td>0.724213</td>\n",
       "      <td>0.769779</td>\n",
       "      <td>0.746301</td>\n",
       "      <td>0.871784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.483000</td>\n",
       "      <td>0.397107</td>\n",
       "      <td>0.724751</td>\n",
       "      <td>0.770256</td>\n",
       "      <td>0.746811</td>\n",
       "      <td>0.872262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.483000</td>\n",
       "      <td>0.395973</td>\n",
       "      <td>0.724714</td>\n",
       "      <td>0.770343</td>\n",
       "      <td>0.746832</td>\n",
       "      <td>0.872396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.475500</td>\n",
       "      <td>0.395212</td>\n",
       "      <td>0.725215</td>\n",
       "      <td>0.770560</td>\n",
       "      <td>0.747200</td>\n",
       "      <td>0.872591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.475500</td>\n",
       "      <td>0.394937</td>\n",
       "      <td>0.725374</td>\n",
       "      <td>0.770604</td>\n",
       "      <td>0.747305</td>\n",
       "      <td>0.872650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ewp/.local/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 5e-05, 'batch_size': 32, 'weight_decay': 0.0}  =  {'precision': 0.3459698196540302, 'recall': 0.4117389399912396, 'f1': 0.376, 'number': 2283}\n",
      "{'learning_rate': 5e-05, 'batch_size': 32, 'weight_decay': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4710' max='4710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4710/4710 22:04, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.554771</td>\n",
       "      <td>0.350761</td>\n",
       "      <td>0.453278</td>\n",
       "      <td>0.395484</td>\n",
       "      <td>0.602158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.127732</td>\n",
       "      <td>0.443322</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.474605</td>\n",
       "      <td>0.697248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.928122</td>\n",
       "      <td>0.499397</td>\n",
       "      <td>0.557273</td>\n",
       "      <td>0.526750</td>\n",
       "      <td>0.736724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.476800</td>\n",
       "      <td>0.809950</td>\n",
       "      <td>0.546938</td>\n",
       "      <td>0.596787</td>\n",
       "      <td>0.570776</td>\n",
       "      <td>0.767235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.476800</td>\n",
       "      <td>0.730647</td>\n",
       "      <td>0.577437</td>\n",
       "      <td>0.628962</td>\n",
       "      <td>0.602099</td>\n",
       "      <td>0.787437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.476800</td>\n",
       "      <td>0.671936</td>\n",
       "      <td>0.602472</td>\n",
       "      <td>0.652019</td>\n",
       "      <td>0.626267</td>\n",
       "      <td>0.802080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.843800</td>\n",
       "      <td>0.626980</td>\n",
       "      <td>0.623594</td>\n",
       "      <td>0.671819</td>\n",
       "      <td>0.646809</td>\n",
       "      <td>0.813197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.843800</td>\n",
       "      <td>0.591804</td>\n",
       "      <td>0.636857</td>\n",
       "      <td>0.683370</td>\n",
       "      <td>0.659294</td>\n",
       "      <td>0.820638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.843800</td>\n",
       "      <td>0.562739</td>\n",
       "      <td>0.650444</td>\n",
       "      <td>0.696396</td>\n",
       "      <td>0.672636</td>\n",
       "      <td>0.827795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.681400</td>\n",
       "      <td>0.538581</td>\n",
       "      <td>0.661136</td>\n",
       "      <td>0.707642</td>\n",
       "      <td>0.683599</td>\n",
       "      <td>0.833727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.681400</td>\n",
       "      <td>0.518196</td>\n",
       "      <td>0.671468</td>\n",
       "      <td>0.718584</td>\n",
       "      <td>0.694228</td>\n",
       "      <td>0.839121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.681400</td>\n",
       "      <td>0.500959</td>\n",
       "      <td>0.677712</td>\n",
       "      <td>0.723795</td>\n",
       "      <td>0.699996</td>\n",
       "      <td>0.843319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.598900</td>\n",
       "      <td>0.485820</td>\n",
       "      <td>0.685272</td>\n",
       "      <td>0.730352</td>\n",
       "      <td>0.707094</td>\n",
       "      <td>0.847369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.598900</td>\n",
       "      <td>0.473561</td>\n",
       "      <td>0.688522</td>\n",
       "      <td>0.733218</td>\n",
       "      <td>0.710167</td>\n",
       "      <td>0.849655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.598900</td>\n",
       "      <td>0.461807</td>\n",
       "      <td>0.695464</td>\n",
       "      <td>0.740339</td>\n",
       "      <td>0.717200</td>\n",
       "      <td>0.853525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.550500</td>\n",
       "      <td>0.452162</td>\n",
       "      <td>0.697243</td>\n",
       "      <td>0.742293</td>\n",
       "      <td>0.719063</td>\n",
       "      <td>0.855632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.550500</td>\n",
       "      <td>0.443045</td>\n",
       "      <td>0.703486</td>\n",
       "      <td>0.747503</td>\n",
       "      <td>0.724827</td>\n",
       "      <td>0.858799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.550500</td>\n",
       "      <td>0.435800</td>\n",
       "      <td>0.705195</td>\n",
       "      <td>0.749197</td>\n",
       "      <td>0.726530</td>\n",
       "      <td>0.860249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.550500</td>\n",
       "      <td>0.428659</td>\n",
       "      <td>0.709962</td>\n",
       "      <td>0.754755</td>\n",
       "      <td>0.731673</td>\n",
       "      <td>0.862789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.518900</td>\n",
       "      <td>0.422452</td>\n",
       "      <td>0.712972</td>\n",
       "      <td>0.757490</td>\n",
       "      <td>0.734557</td>\n",
       "      <td>0.864686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.518900</td>\n",
       "      <td>0.417377</td>\n",
       "      <td>0.714432</td>\n",
       "      <td>0.759010</td>\n",
       "      <td>0.736046</td>\n",
       "      <td>0.865717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.518900</td>\n",
       "      <td>0.412829</td>\n",
       "      <td>0.716796</td>\n",
       "      <td>0.761615</td>\n",
       "      <td>0.738526</td>\n",
       "      <td>0.867212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.497200</td>\n",
       "      <td>0.409195</td>\n",
       "      <td>0.718404</td>\n",
       "      <td>0.762918</td>\n",
       "      <td>0.739992</td>\n",
       "      <td>0.868123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.497200</td>\n",
       "      <td>0.405744</td>\n",
       "      <td>0.721019</td>\n",
       "      <td>0.764568</td>\n",
       "      <td>0.742155</td>\n",
       "      <td>0.869348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.497200</td>\n",
       "      <td>0.402819</td>\n",
       "      <td>0.723457</td>\n",
       "      <td>0.767217</td>\n",
       "      <td>0.744695</td>\n",
       "      <td>0.870514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.484800</td>\n",
       "      <td>0.400691</td>\n",
       "      <td>0.724131</td>\n",
       "      <td>0.767868</td>\n",
       "      <td>0.745358</td>\n",
       "      <td>0.870962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.484800</td>\n",
       "      <td>0.398899</td>\n",
       "      <td>0.725362</td>\n",
       "      <td>0.768954</td>\n",
       "      <td>0.746522</td>\n",
       "      <td>0.871694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.484800</td>\n",
       "      <td>0.397768</td>\n",
       "      <td>0.725876</td>\n",
       "      <td>0.769214</td>\n",
       "      <td>0.746917</td>\n",
       "      <td>0.871918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.477300</td>\n",
       "      <td>0.397012</td>\n",
       "      <td>0.725972</td>\n",
       "      <td>0.769127</td>\n",
       "      <td>0.746927</td>\n",
       "      <td>0.872038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.477300</td>\n",
       "      <td>0.396734</td>\n",
       "      <td>0.726136</td>\n",
       "      <td>0.769301</td>\n",
       "      <td>0.747096</td>\n",
       "      <td>0.872127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 5e-05, 'batch_size': 32, 'weight_decay': 0.1}  =  {'precision': 0.34435869165747884, 'recall': 0.41042487954445905, 'f1': 0.3745003996802558, 'number': 2283}\n",
      "{'learning_rate': 5e-05, 'batch_size': 32, 'weight_decay': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4710' max='4710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4710/4710 21:59, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.554600</td>\n",
       "      <td>0.350726</td>\n",
       "      <td>0.453278</td>\n",
       "      <td>0.395462</td>\n",
       "      <td>0.602158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.127411</td>\n",
       "      <td>0.443376</td>\n",
       "      <td>0.510682</td>\n",
       "      <td>0.474655</td>\n",
       "      <td>0.697263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.927700</td>\n",
       "      <td>0.499397</td>\n",
       "      <td>0.557186</td>\n",
       "      <td>0.526711</td>\n",
       "      <td>0.736739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.476600</td>\n",
       "      <td>0.809431</td>\n",
       "      <td>0.547101</td>\n",
       "      <td>0.596917</td>\n",
       "      <td>0.570924</td>\n",
       "      <td>0.767280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.476600</td>\n",
       "      <td>0.730051</td>\n",
       "      <td>0.577523</td>\n",
       "      <td>0.629006</td>\n",
       "      <td>0.602166</td>\n",
       "      <td>0.787497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.476600</td>\n",
       "      <td>0.671277</td>\n",
       "      <td>0.602728</td>\n",
       "      <td>0.652323</td>\n",
       "      <td>0.626546</td>\n",
       "      <td>0.802259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.843300</td>\n",
       "      <td>0.626269</td>\n",
       "      <td>0.623630</td>\n",
       "      <td>0.671993</td>\n",
       "      <td>0.646909</td>\n",
       "      <td>0.813271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.843300</td>\n",
       "      <td>0.591052</td>\n",
       "      <td>0.636967</td>\n",
       "      <td>0.683543</td>\n",
       "      <td>0.659434</td>\n",
       "      <td>0.820683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.843300</td>\n",
       "      <td>0.561950</td>\n",
       "      <td>0.650537</td>\n",
       "      <td>0.696439</td>\n",
       "      <td>0.672706</td>\n",
       "      <td>0.827840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.680700</td>\n",
       "      <td>0.537764</td>\n",
       "      <td>0.661325</td>\n",
       "      <td>0.707816</td>\n",
       "      <td>0.683781</td>\n",
       "      <td>0.833787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.680700</td>\n",
       "      <td>0.517353</td>\n",
       "      <td>0.671766</td>\n",
       "      <td>0.718845</td>\n",
       "      <td>0.694509</td>\n",
       "      <td>0.839285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.680700</td>\n",
       "      <td>0.500096</td>\n",
       "      <td>0.678066</td>\n",
       "      <td>0.724056</td>\n",
       "      <td>0.700307</td>\n",
       "      <td>0.843424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.598000</td>\n",
       "      <td>0.484941</td>\n",
       "      <td>0.685501</td>\n",
       "      <td>0.730656</td>\n",
       "      <td>0.707359</td>\n",
       "      <td>0.847518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.598000</td>\n",
       "      <td>0.472666</td>\n",
       "      <td>0.688917</td>\n",
       "      <td>0.733608</td>\n",
       "      <td>0.710561</td>\n",
       "      <td>0.849969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.598000</td>\n",
       "      <td>0.460899</td>\n",
       "      <td>0.695697</td>\n",
       "      <td>0.740556</td>\n",
       "      <td>0.717426</td>\n",
       "      <td>0.853644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.549500</td>\n",
       "      <td>0.451243</td>\n",
       "      <td>0.697475</td>\n",
       "      <td>0.742510</td>\n",
       "      <td>0.719288</td>\n",
       "      <td>0.855826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.549500</td>\n",
       "      <td>0.442117</td>\n",
       "      <td>0.703620</td>\n",
       "      <td>0.747677</td>\n",
       "      <td>0.724980</td>\n",
       "      <td>0.858889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.549500</td>\n",
       "      <td>0.434867</td>\n",
       "      <td>0.705116</td>\n",
       "      <td>0.749327</td>\n",
       "      <td>0.726549</td>\n",
       "      <td>0.860368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.549500</td>\n",
       "      <td>0.427719</td>\n",
       "      <td>0.710033</td>\n",
       "      <td>0.755015</td>\n",
       "      <td>0.731834</td>\n",
       "      <td>0.862908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.518000</td>\n",
       "      <td>0.421506</td>\n",
       "      <td>0.713422</td>\n",
       "      <td>0.757968</td>\n",
       "      <td>0.735020</td>\n",
       "      <td>0.864881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.518000</td>\n",
       "      <td>0.416428</td>\n",
       "      <td>0.714607</td>\n",
       "      <td>0.759444</td>\n",
       "      <td>0.736344</td>\n",
       "      <td>0.865912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.518000</td>\n",
       "      <td>0.411876</td>\n",
       "      <td>0.717251</td>\n",
       "      <td>0.762223</td>\n",
       "      <td>0.739054</td>\n",
       "      <td>0.867451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.496200</td>\n",
       "      <td>0.408241</td>\n",
       "      <td>0.718520</td>\n",
       "      <td>0.763135</td>\n",
       "      <td>0.740156</td>\n",
       "      <td>0.868257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.496200</td>\n",
       "      <td>0.404788</td>\n",
       "      <td>0.721435</td>\n",
       "      <td>0.764915</td>\n",
       "      <td>0.742539</td>\n",
       "      <td>0.869528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.496200</td>\n",
       "      <td>0.401861</td>\n",
       "      <td>0.723904</td>\n",
       "      <td>0.767564</td>\n",
       "      <td>0.745095</td>\n",
       "      <td>0.870693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.483800</td>\n",
       "      <td>0.399732</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.768346</td>\n",
       "      <td>0.745916</td>\n",
       "      <td>0.871246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.483800</td>\n",
       "      <td>0.397941</td>\n",
       "      <td>0.725787</td>\n",
       "      <td>0.769214</td>\n",
       "      <td>0.746870</td>\n",
       "      <td>0.871829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.483800</td>\n",
       "      <td>0.396809</td>\n",
       "      <td>0.726192</td>\n",
       "      <td>0.769518</td>\n",
       "      <td>0.747228</td>\n",
       "      <td>0.872098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.476300</td>\n",
       "      <td>0.396053</td>\n",
       "      <td>0.726691</td>\n",
       "      <td>0.769605</td>\n",
       "      <td>0.747533</td>\n",
       "      <td>0.872441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.476300</td>\n",
       "      <td>0.395775</td>\n",
       "      <td>0.726773</td>\n",
       "      <td>0.769692</td>\n",
       "      <td>0.747617</td>\n",
       "      <td>0.872441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 5e-05, 'batch_size': 32, 'weight_decay': 0.01}  =  {'precision': 0.34472620360161704, 'recall': 0.4108628996933859, 'f1': 0.3749000799360512, 'number': 2283}\n",
      "{'learning_rate': 0.0002, 'batch_size': 32, 'weight_decay': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4710' max='4710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4710/4710 22:02, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.793150</td>\n",
       "      <td>0.555234</td>\n",
       "      <td>0.600391</td>\n",
       "      <td>0.576930</td>\n",
       "      <td>0.771852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.566179</td>\n",
       "      <td>0.648535</td>\n",
       "      <td>0.696830</td>\n",
       "      <td>0.671816</td>\n",
       "      <td>0.826943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.471772</td>\n",
       "      <td>0.687943</td>\n",
       "      <td>0.737082</td>\n",
       "      <td>0.711665</td>\n",
       "      <td>0.850536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.884100</td>\n",
       "      <td>0.416310</td>\n",
       "      <td>0.718657</td>\n",
       "      <td>0.763873</td>\n",
       "      <td>0.740575</td>\n",
       "      <td>0.867720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.884100</td>\n",
       "      <td>0.382014</td>\n",
       "      <td>0.730884</td>\n",
       "      <td>0.776552</td>\n",
       "      <td>0.753026</td>\n",
       "      <td>0.875848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.884100</td>\n",
       "      <td>0.354537</td>\n",
       "      <td>0.748751</td>\n",
       "      <td>0.793878</td>\n",
       "      <td>0.770654</td>\n",
       "      <td>0.885754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.471500</td>\n",
       "      <td>0.334705</td>\n",
       "      <td>0.761746</td>\n",
       "      <td>0.802562</td>\n",
       "      <td>0.781621</td>\n",
       "      <td>0.891910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.471500</td>\n",
       "      <td>0.319698</td>\n",
       "      <td>0.766639</td>\n",
       "      <td>0.807251</td>\n",
       "      <td>0.786421</td>\n",
       "      <td>0.895272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.471500</td>\n",
       "      <td>0.307250</td>\n",
       "      <td>0.773192</td>\n",
       "      <td>0.811767</td>\n",
       "      <td>0.792010</td>\n",
       "      <td>0.899157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.399700</td>\n",
       "      <td>0.296985</td>\n",
       "      <td>0.779206</td>\n",
       "      <td>0.818454</td>\n",
       "      <td>0.798348</td>\n",
       "      <td>0.902116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.399700</td>\n",
       "      <td>0.287334</td>\n",
       "      <td>0.784138</td>\n",
       "      <td>0.822579</td>\n",
       "      <td>0.802899</td>\n",
       "      <td>0.904880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.399700</td>\n",
       "      <td>0.279863</td>\n",
       "      <td>0.787285</td>\n",
       "      <td>0.825402</td>\n",
       "      <td>0.805893</td>\n",
       "      <td>0.907091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.363600</td>\n",
       "      <td>0.273291</td>\n",
       "      <td>0.791058</td>\n",
       "      <td>0.829700</td>\n",
       "      <td>0.809918</td>\n",
       "      <td>0.909094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.363600</td>\n",
       "      <td>0.269158</td>\n",
       "      <td>0.792388</td>\n",
       "      <td>0.832610</td>\n",
       "      <td>0.812001</td>\n",
       "      <td>0.910169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.363600</td>\n",
       "      <td>0.263759</td>\n",
       "      <td>0.795517</td>\n",
       "      <td>0.835172</td>\n",
       "      <td>0.814862</td>\n",
       "      <td>0.912007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.344200</td>\n",
       "      <td>0.259148</td>\n",
       "      <td>0.798492</td>\n",
       "      <td>0.837082</td>\n",
       "      <td>0.817332</td>\n",
       "      <td>0.913516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.344200</td>\n",
       "      <td>0.254973</td>\n",
       "      <td>0.800207</td>\n",
       "      <td>0.839123</td>\n",
       "      <td>0.819203</td>\n",
       "      <td>0.914906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.344200</td>\n",
       "      <td>0.252661</td>\n",
       "      <td>0.800589</td>\n",
       "      <td>0.838341</td>\n",
       "      <td>0.819030</td>\n",
       "      <td>0.915145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.344200</td>\n",
       "      <td>0.249105</td>\n",
       "      <td>0.803780</td>\n",
       "      <td>0.842032</td>\n",
       "      <td>0.822462</td>\n",
       "      <td>0.916415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.331300</td>\n",
       "      <td>0.245758</td>\n",
       "      <td>0.806173</td>\n",
       "      <td>0.843769</td>\n",
       "      <td>0.824543</td>\n",
       "      <td>0.917491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.331300</td>\n",
       "      <td>0.243745</td>\n",
       "      <td>0.807434</td>\n",
       "      <td>0.845158</td>\n",
       "      <td>0.825866</td>\n",
       "      <td>0.918178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.331300</td>\n",
       "      <td>0.242099</td>\n",
       "      <td>0.807528</td>\n",
       "      <td>0.845853</td>\n",
       "      <td>0.826246</td>\n",
       "      <td>0.918432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.322300</td>\n",
       "      <td>0.240752</td>\n",
       "      <td>0.809162</td>\n",
       "      <td>0.845983</td>\n",
       "      <td>0.827163</td>\n",
       "      <td>0.919060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.322300</td>\n",
       "      <td>0.239438</td>\n",
       "      <td>0.810119</td>\n",
       "      <td>0.846809</td>\n",
       "      <td>0.828058</td>\n",
       "      <td>0.919538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.322300</td>\n",
       "      <td>0.237546</td>\n",
       "      <td>0.810229</td>\n",
       "      <td>0.848155</td>\n",
       "      <td>0.828758</td>\n",
       "      <td>0.919882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.318700</td>\n",
       "      <td>0.237397</td>\n",
       "      <td>0.810948</td>\n",
       "      <td>0.847851</td>\n",
       "      <td>0.828989</td>\n",
       "      <td>0.920166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.318700</td>\n",
       "      <td>0.236545</td>\n",
       "      <td>0.811817</td>\n",
       "      <td>0.848372</td>\n",
       "      <td>0.829692</td>\n",
       "      <td>0.920539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.318700</td>\n",
       "      <td>0.236003</td>\n",
       "      <td>0.811065</td>\n",
       "      <td>0.848502</td>\n",
       "      <td>0.829361</td>\n",
       "      <td>0.920554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.315100</td>\n",
       "      <td>0.235631</td>\n",
       "      <td>0.811557</td>\n",
       "      <td>0.848241</td>\n",
       "      <td>0.829494</td>\n",
       "      <td>0.920554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.315100</td>\n",
       "      <td>0.235500</td>\n",
       "      <td>0.811713</td>\n",
       "      <td>0.848545</td>\n",
       "      <td>0.829721</td>\n",
       "      <td>0.920674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.0002, 'batch_size': 32, 'weight_decay': 0.0}  =  {'precision': 0.45150247242297453, 'recall': 0.5199299167761717, 'f1': 0.4833061889250814, 'number': 2283}\n",
      "{'learning_rate': 0.0002, 'batch_size': 32, 'weight_decay': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4710' max='4710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4710/4710 21:59, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.793737</td>\n",
       "      <td>0.555083</td>\n",
       "      <td>0.600130</td>\n",
       "      <td>0.576728</td>\n",
       "      <td>0.771763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.567074</td>\n",
       "      <td>0.648547</td>\n",
       "      <td>0.696787</td>\n",
       "      <td>0.671802</td>\n",
       "      <td>0.826928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.472848</td>\n",
       "      <td>0.687769</td>\n",
       "      <td>0.736865</td>\n",
       "      <td>0.711471</td>\n",
       "      <td>0.850447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.884800</td>\n",
       "      <td>0.417525</td>\n",
       "      <td>0.718343</td>\n",
       "      <td>0.763352</td>\n",
       "      <td>0.740164</td>\n",
       "      <td>0.867495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.884800</td>\n",
       "      <td>0.383332</td>\n",
       "      <td>0.730475</td>\n",
       "      <td>0.776118</td>\n",
       "      <td>0.752605</td>\n",
       "      <td>0.875639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.884800</td>\n",
       "      <td>0.355944</td>\n",
       "      <td>0.748219</td>\n",
       "      <td>0.793313</td>\n",
       "      <td>0.770106</td>\n",
       "      <td>0.885411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.472800</td>\n",
       "      <td>0.336194</td>\n",
       "      <td>0.761316</td>\n",
       "      <td>0.801911</td>\n",
       "      <td>0.781086</td>\n",
       "      <td>0.891432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.472800</td>\n",
       "      <td>0.321235</td>\n",
       "      <td>0.766302</td>\n",
       "      <td>0.806730</td>\n",
       "      <td>0.785997</td>\n",
       "      <td>0.895063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.472800</td>\n",
       "      <td>0.308858</td>\n",
       "      <td>0.773075</td>\n",
       "      <td>0.811376</td>\n",
       "      <td>0.791763</td>\n",
       "      <td>0.898858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.298640</td>\n",
       "      <td>0.778673</td>\n",
       "      <td>0.818063</td>\n",
       "      <td>0.797882</td>\n",
       "      <td>0.901892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.289041</td>\n",
       "      <td>0.783660</td>\n",
       "      <td>0.822145</td>\n",
       "      <td>0.802441</td>\n",
       "      <td>0.904611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.281611</td>\n",
       "      <td>0.787117</td>\n",
       "      <td>0.825054</td>\n",
       "      <td>0.805639</td>\n",
       "      <td>0.906778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.365400</td>\n",
       "      <td>0.275069</td>\n",
       "      <td>0.790694</td>\n",
       "      <td>0.829353</td>\n",
       "      <td>0.809562</td>\n",
       "      <td>0.908765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.365400</td>\n",
       "      <td>0.270962</td>\n",
       "      <td>0.791627</td>\n",
       "      <td>0.831741</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.909766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.365400</td>\n",
       "      <td>0.265601</td>\n",
       "      <td>0.795274</td>\n",
       "      <td>0.834433</td>\n",
       "      <td>0.814383</td>\n",
       "      <td>0.911708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.346100</td>\n",
       "      <td>0.261020</td>\n",
       "      <td>0.798028</td>\n",
       "      <td>0.836387</td>\n",
       "      <td>0.816757</td>\n",
       "      <td>0.913173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.346100</td>\n",
       "      <td>0.256870</td>\n",
       "      <td>0.800091</td>\n",
       "      <td>0.838689</td>\n",
       "      <td>0.818935</td>\n",
       "      <td>0.914547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.346100</td>\n",
       "      <td>0.254579</td>\n",
       "      <td>0.799801</td>\n",
       "      <td>0.837343</td>\n",
       "      <td>0.818141</td>\n",
       "      <td>0.914667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.346100</td>\n",
       "      <td>0.251052</td>\n",
       "      <td>0.802984</td>\n",
       "      <td>0.841164</td>\n",
       "      <td>0.821631</td>\n",
       "      <td>0.915862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.333200</td>\n",
       "      <td>0.247721</td>\n",
       "      <td>0.805217</td>\n",
       "      <td>0.843118</td>\n",
       "      <td>0.823732</td>\n",
       "      <td>0.916998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.333200</td>\n",
       "      <td>0.245718</td>\n",
       "      <td>0.806895</td>\n",
       "      <td>0.844594</td>\n",
       "      <td>0.825314</td>\n",
       "      <td>0.917835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.333200</td>\n",
       "      <td>0.244093</td>\n",
       "      <td>0.807340</td>\n",
       "      <td>0.845376</td>\n",
       "      <td>0.825920</td>\n",
       "      <td>0.918268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.324300</td>\n",
       "      <td>0.242752</td>\n",
       "      <td>0.808491</td>\n",
       "      <td>0.845072</td>\n",
       "      <td>0.826377</td>\n",
       "      <td>0.918612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.324300</td>\n",
       "      <td>0.241456</td>\n",
       "      <td>0.809170</td>\n",
       "      <td>0.846027</td>\n",
       "      <td>0.827188</td>\n",
       "      <td>0.919030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.324300</td>\n",
       "      <td>0.239571</td>\n",
       "      <td>0.809708</td>\n",
       "      <td>0.847503</td>\n",
       "      <td>0.828174</td>\n",
       "      <td>0.919538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.320600</td>\n",
       "      <td>0.239423</td>\n",
       "      <td>0.810016</td>\n",
       "      <td>0.846982</td>\n",
       "      <td>0.828087</td>\n",
       "      <td>0.919672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.320600</td>\n",
       "      <td>0.238576</td>\n",
       "      <td>0.810483</td>\n",
       "      <td>0.847330</td>\n",
       "      <td>0.828497</td>\n",
       "      <td>0.919867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.320600</td>\n",
       "      <td>0.238036</td>\n",
       "      <td>0.810492</td>\n",
       "      <td>0.847937</td>\n",
       "      <td>0.828792</td>\n",
       "      <td>0.920076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>0.237668</td>\n",
       "      <td>0.810948</td>\n",
       "      <td>0.847851</td>\n",
       "      <td>0.828989</td>\n",
       "      <td>0.920076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>0.237537</td>\n",
       "      <td>0.810641</td>\n",
       "      <td>0.847460</td>\n",
       "      <td>0.828642</td>\n",
       "      <td>0.920061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.0002, 'batch_size': 32, 'weight_decay': 0.1}  =  {'precision': 0.4514285714285714, 'recall': 0.519053876478318, 'f1': 0.4828850855745721, 'number': 2283}\n",
      "{'learning_rate': 0.0002, 'batch_size': 32, 'weight_decay': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4710' max='4710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4710/4710 22:01, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.793209</td>\n",
       "      <td>0.555194</td>\n",
       "      <td>0.600347</td>\n",
       "      <td>0.576889</td>\n",
       "      <td>0.771838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.566269</td>\n",
       "      <td>0.648468</td>\n",
       "      <td>0.696787</td>\n",
       "      <td>0.671760</td>\n",
       "      <td>0.826928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.471880</td>\n",
       "      <td>0.687847</td>\n",
       "      <td>0.737039</td>\n",
       "      <td>0.711594</td>\n",
       "      <td>0.850507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.884100</td>\n",
       "      <td>0.416431</td>\n",
       "      <td>0.718604</td>\n",
       "      <td>0.763786</td>\n",
       "      <td>0.740507</td>\n",
       "      <td>0.867705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.884100</td>\n",
       "      <td>0.382145</td>\n",
       "      <td>0.730884</td>\n",
       "      <td>0.776552</td>\n",
       "      <td>0.753026</td>\n",
       "      <td>0.875848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.884100</td>\n",
       "      <td>0.354677</td>\n",
       "      <td>0.748751</td>\n",
       "      <td>0.793878</td>\n",
       "      <td>0.770654</td>\n",
       "      <td>0.885739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.471600</td>\n",
       "      <td>0.334853</td>\n",
       "      <td>0.761632</td>\n",
       "      <td>0.802475</td>\n",
       "      <td>0.781520</td>\n",
       "      <td>0.891821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.471600</td>\n",
       "      <td>0.319851</td>\n",
       "      <td>0.766630</td>\n",
       "      <td>0.807208</td>\n",
       "      <td>0.786396</td>\n",
       "      <td>0.895243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.471600</td>\n",
       "      <td>0.307410</td>\n",
       "      <td>0.773160</td>\n",
       "      <td>0.811767</td>\n",
       "      <td>0.791993</td>\n",
       "      <td>0.899127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.399900</td>\n",
       "      <td>0.297150</td>\n",
       "      <td>0.779206</td>\n",
       "      <td>0.818454</td>\n",
       "      <td>0.798348</td>\n",
       "      <td>0.902101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.399900</td>\n",
       "      <td>0.287504</td>\n",
       "      <td>0.784023</td>\n",
       "      <td>0.822492</td>\n",
       "      <td>0.802797</td>\n",
       "      <td>0.904850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.399900</td>\n",
       "      <td>0.280037</td>\n",
       "      <td>0.787285</td>\n",
       "      <td>0.825402</td>\n",
       "      <td>0.805893</td>\n",
       "      <td>0.907076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.363800</td>\n",
       "      <td>0.273468</td>\n",
       "      <td>0.790951</td>\n",
       "      <td>0.829657</td>\n",
       "      <td>0.809842</td>\n",
       "      <td>0.909034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.363800</td>\n",
       "      <td>0.269337</td>\n",
       "      <td>0.792305</td>\n",
       "      <td>0.832523</td>\n",
       "      <td>0.811916</td>\n",
       "      <td>0.910154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.363800</td>\n",
       "      <td>0.263942</td>\n",
       "      <td>0.795491</td>\n",
       "      <td>0.835041</td>\n",
       "      <td>0.814787</td>\n",
       "      <td>0.911977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.344400</td>\n",
       "      <td>0.259334</td>\n",
       "      <td>0.798459</td>\n",
       "      <td>0.837082</td>\n",
       "      <td>0.817315</td>\n",
       "      <td>0.913531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.344400</td>\n",
       "      <td>0.255161</td>\n",
       "      <td>0.800190</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.819153</td>\n",
       "      <td>0.914891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.344400</td>\n",
       "      <td>0.252852</td>\n",
       "      <td>0.800523</td>\n",
       "      <td>0.838168</td>\n",
       "      <td>0.818913</td>\n",
       "      <td>0.915026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.344400</td>\n",
       "      <td>0.249298</td>\n",
       "      <td>0.803523</td>\n",
       "      <td>0.841902</td>\n",
       "      <td>0.822265</td>\n",
       "      <td>0.916296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.331500</td>\n",
       "      <td>0.245953</td>\n",
       "      <td>0.806173</td>\n",
       "      <td>0.843769</td>\n",
       "      <td>0.824543</td>\n",
       "      <td>0.917491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.331500</td>\n",
       "      <td>0.243941</td>\n",
       "      <td>0.807467</td>\n",
       "      <td>0.845158</td>\n",
       "      <td>0.825883</td>\n",
       "      <td>0.918178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.331500</td>\n",
       "      <td>0.242297</td>\n",
       "      <td>0.807353</td>\n",
       "      <td>0.845810</td>\n",
       "      <td>0.826134</td>\n",
       "      <td>0.918373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.322500</td>\n",
       "      <td>0.240951</td>\n",
       "      <td>0.809012</td>\n",
       "      <td>0.845897</td>\n",
       "      <td>0.827043</td>\n",
       "      <td>0.918970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.322500</td>\n",
       "      <td>0.239639</td>\n",
       "      <td>0.809793</td>\n",
       "      <td>0.846678</td>\n",
       "      <td>0.827825</td>\n",
       "      <td>0.919433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.322500</td>\n",
       "      <td>0.237747</td>\n",
       "      <td>0.810112</td>\n",
       "      <td>0.848068</td>\n",
       "      <td>0.828656</td>\n",
       "      <td>0.919837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.318900</td>\n",
       "      <td>0.237598</td>\n",
       "      <td>0.810800</td>\n",
       "      <td>0.847590</td>\n",
       "      <td>0.828787</td>\n",
       "      <td>0.920106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.318900</td>\n",
       "      <td>0.236747</td>\n",
       "      <td>0.811817</td>\n",
       "      <td>0.848372</td>\n",
       "      <td>0.829692</td>\n",
       "      <td>0.920509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.318900</td>\n",
       "      <td>0.236205</td>\n",
       "      <td>0.811058</td>\n",
       "      <td>0.848459</td>\n",
       "      <td>0.829337</td>\n",
       "      <td>0.920494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.315300</td>\n",
       "      <td>0.235834</td>\n",
       "      <td>0.811557</td>\n",
       "      <td>0.848241</td>\n",
       "      <td>0.829494</td>\n",
       "      <td>0.920509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.315300</td>\n",
       "      <td>0.235703</td>\n",
       "      <td>0.811622</td>\n",
       "      <td>0.848415</td>\n",
       "      <td>0.829611</td>\n",
       "      <td>0.920644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.0002, 'batch_size': 32, 'weight_decay': 0.01}  =  {'precision': 0.4516742770167428, 'recall': 0.5199299167761717, 'f1': 0.4834046019140705, 'number': 2283}\n",
      "{'learning_rate': 0.002, 'batch_size': 32, 'weight_decay': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4710' max='4710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4710/4710 22:03, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.290119</td>\n",
       "      <td>0.772824</td>\n",
       "      <td>0.818194</td>\n",
       "      <td>0.794862</td>\n",
       "      <td>0.901817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.232832</td>\n",
       "      <td>0.807868</td>\n",
       "      <td>0.844420</td>\n",
       "      <td>0.825740</td>\n",
       "      <td>0.920390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.206397</td>\n",
       "      <td>0.826304</td>\n",
       "      <td>0.860964</td>\n",
       "      <td>0.843278</td>\n",
       "      <td>0.929639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.399200</td>\n",
       "      <td>0.198015</td>\n",
       "      <td>0.831244</td>\n",
       "      <td>0.866652</td>\n",
       "      <td>0.848579</td>\n",
       "      <td>0.931402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.399200</td>\n",
       "      <td>0.185118</td>\n",
       "      <td>0.841312</td>\n",
       "      <td>0.879852</td>\n",
       "      <td>0.860151</td>\n",
       "      <td>0.937364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.399200</td>\n",
       "      <td>0.181339</td>\n",
       "      <td>0.843809</td>\n",
       "      <td>0.871472</td>\n",
       "      <td>0.857417</td>\n",
       "      <td>0.936900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.276300</td>\n",
       "      <td>0.177397</td>\n",
       "      <td>0.845052</td>\n",
       "      <td>0.881416</td>\n",
       "      <td>0.862851</td>\n",
       "      <td>0.939142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.276300</td>\n",
       "      <td>0.171422</td>\n",
       "      <td>0.850811</td>\n",
       "      <td>0.881806</td>\n",
       "      <td>0.866031</td>\n",
       "      <td>0.941981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.276300</td>\n",
       "      <td>0.168917</td>\n",
       "      <td>0.854292</td>\n",
       "      <td>0.884672</td>\n",
       "      <td>0.869216</td>\n",
       "      <td>0.942160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.264400</td>\n",
       "      <td>0.166397</td>\n",
       "      <td>0.858541</td>\n",
       "      <td>0.887581</td>\n",
       "      <td>0.872820</td>\n",
       "      <td>0.943161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.264400</td>\n",
       "      <td>0.164193</td>\n",
       "      <td>0.857854</td>\n",
       "      <td>0.889926</td>\n",
       "      <td>0.873596</td>\n",
       "      <td>0.943490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.264400</td>\n",
       "      <td>0.164972</td>\n",
       "      <td>0.855397</td>\n",
       "      <td>0.884368</td>\n",
       "      <td>0.869641</td>\n",
       "      <td>0.942698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.258400</td>\n",
       "      <td>0.166627</td>\n",
       "      <td>0.851889</td>\n",
       "      <td>0.880113</td>\n",
       "      <td>0.865771</td>\n",
       "      <td>0.942085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.258400</td>\n",
       "      <td>0.165850</td>\n",
       "      <td>0.852602</td>\n",
       "      <td>0.892141</td>\n",
       "      <td>0.871923</td>\n",
       "      <td>0.942115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.258400</td>\n",
       "      <td>0.161200</td>\n",
       "      <td>0.862107</td>\n",
       "      <td>0.887712</td>\n",
       "      <td>0.874722</td>\n",
       "      <td>0.945029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.256500</td>\n",
       "      <td>0.161242</td>\n",
       "      <td>0.862002</td>\n",
       "      <td>0.889101</td>\n",
       "      <td>0.875342</td>\n",
       "      <td>0.944805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.256500</td>\n",
       "      <td>0.156199</td>\n",
       "      <td>0.861808</td>\n",
       "      <td>0.894963</td>\n",
       "      <td>0.878073</td>\n",
       "      <td>0.947315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.256500</td>\n",
       "      <td>0.156624</td>\n",
       "      <td>0.861622</td>\n",
       "      <td>0.891403</td>\n",
       "      <td>0.876259</td>\n",
       "      <td>0.946194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.256500</td>\n",
       "      <td>0.156105</td>\n",
       "      <td>0.859449</td>\n",
       "      <td>0.894789</td>\n",
       "      <td>0.876763</td>\n",
       "      <td>0.946359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.254200</td>\n",
       "      <td>0.157896</td>\n",
       "      <td>0.859317</td>\n",
       "      <td>0.890100</td>\n",
       "      <td>0.874437</td>\n",
       "      <td>0.945328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.254200</td>\n",
       "      <td>0.156458</td>\n",
       "      <td>0.862525</td>\n",
       "      <td>0.889752</td>\n",
       "      <td>0.875927</td>\n",
       "      <td>0.946135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.254200</td>\n",
       "      <td>0.154760</td>\n",
       "      <td>0.863427</td>\n",
       "      <td>0.896570</td>\n",
       "      <td>0.879686</td>\n",
       "      <td>0.947076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.252500</td>\n",
       "      <td>0.154930</td>\n",
       "      <td>0.864925</td>\n",
       "      <td>0.892792</td>\n",
       "      <td>0.878638</td>\n",
       "      <td>0.946792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.252500</td>\n",
       "      <td>0.155431</td>\n",
       "      <td>0.863025</td>\n",
       "      <td>0.891055</td>\n",
       "      <td>0.876816</td>\n",
       "      <td>0.946777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.252500</td>\n",
       "      <td>0.154870</td>\n",
       "      <td>0.860561</td>\n",
       "      <td>0.893183</td>\n",
       "      <td>0.876569</td>\n",
       "      <td>0.946687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.252600</td>\n",
       "      <td>0.154568</td>\n",
       "      <td>0.864637</td>\n",
       "      <td>0.893921</td>\n",
       "      <td>0.879035</td>\n",
       "      <td>0.947121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.252600</td>\n",
       "      <td>0.154607</td>\n",
       "      <td>0.864829</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.878903</td>\n",
       "      <td>0.946912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.252600</td>\n",
       "      <td>0.154004</td>\n",
       "      <td>0.864323</td>\n",
       "      <td>0.894572</td>\n",
       "      <td>0.879187</td>\n",
       "      <td>0.947345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.250600</td>\n",
       "      <td>0.154851</td>\n",
       "      <td>0.863822</td>\n",
       "      <td>0.892141</td>\n",
       "      <td>0.877753</td>\n",
       "      <td>0.946777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.250600</td>\n",
       "      <td>0.154432</td>\n",
       "      <td>0.864959</td>\n",
       "      <td>0.893053</td>\n",
       "      <td>0.878781</td>\n",
       "      <td>0.947195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.002, 'batch_size': 32, 'weight_decay': 0.0}  =  {'precision': 0.5311284046692607, 'recall': 0.5978975032851511, 'f1': 0.5625386358953225, 'number': 2283}\n",
      "{'learning_rate': 0.002, 'batch_size': 32, 'weight_decay': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4710' max='4710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4710/4710 22:03, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.291966</td>\n",
       "      <td>0.772522</td>\n",
       "      <td>0.817673</td>\n",
       "      <td>0.794456</td>\n",
       "      <td>0.901533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.235690</td>\n",
       "      <td>0.806754</td>\n",
       "      <td>0.843291</td>\n",
       "      <td>0.824618</td>\n",
       "      <td>0.919852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.209906</td>\n",
       "      <td>0.824733</td>\n",
       "      <td>0.859184</td>\n",
       "      <td>0.841606</td>\n",
       "      <td>0.928742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.202060</td>\n",
       "      <td>0.828342</td>\n",
       "      <td>0.864742</td>\n",
       "      <td>0.846151</td>\n",
       "      <td>0.930042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.189535</td>\n",
       "      <td>0.839590</td>\n",
       "      <td>0.877942</td>\n",
       "      <td>0.858338</td>\n",
       "      <td>0.936303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.185921</td>\n",
       "      <td>0.842172</td>\n",
       "      <td>0.869561</td>\n",
       "      <td>0.855647</td>\n",
       "      <td>0.935840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.279600</td>\n",
       "      <td>0.182935</td>\n",
       "      <td>0.841862</td>\n",
       "      <td>0.877942</td>\n",
       "      <td>0.859523</td>\n",
       "      <td>0.937438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.279600</td>\n",
       "      <td>0.176660</td>\n",
       "      <td>0.848600</td>\n",
       "      <td>0.879331</td>\n",
       "      <td>0.863693</td>\n",
       "      <td>0.940606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.279600</td>\n",
       "      <td>0.174496</td>\n",
       "      <td>0.851271</td>\n",
       "      <td>0.881285</td>\n",
       "      <td>0.866018</td>\n",
       "      <td>0.940397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.267800</td>\n",
       "      <td>0.172401</td>\n",
       "      <td>0.855349</td>\n",
       "      <td>0.884542</td>\n",
       "      <td>0.869701</td>\n",
       "      <td>0.941219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.267800</td>\n",
       "      <td>0.170336</td>\n",
       "      <td>0.854688</td>\n",
       "      <td>0.887495</td>\n",
       "      <td>0.870782</td>\n",
       "      <td>0.941861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.267800</td>\n",
       "      <td>0.171329</td>\n",
       "      <td>0.850778</td>\n",
       "      <td>0.881329</td>\n",
       "      <td>0.865784</td>\n",
       "      <td>0.940636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.261800</td>\n",
       "      <td>0.173493</td>\n",
       "      <td>0.847230</td>\n",
       "      <td>0.875337</td>\n",
       "      <td>0.861054</td>\n",
       "      <td>0.939620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.261800</td>\n",
       "      <td>0.172561</td>\n",
       "      <td>0.847756</td>\n",
       "      <td>0.889058</td>\n",
       "      <td>0.867916</td>\n",
       "      <td>0.939665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.261800</td>\n",
       "      <td>0.168110</td>\n",
       "      <td>0.857950</td>\n",
       "      <td>0.883804</td>\n",
       "      <td>0.870685</td>\n",
       "      <td>0.942862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.259800</td>\n",
       "      <td>0.167907</td>\n",
       "      <td>0.857221</td>\n",
       "      <td>0.885845</td>\n",
       "      <td>0.871298</td>\n",
       "      <td>0.942623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.259800</td>\n",
       "      <td>0.163206</td>\n",
       "      <td>0.857877</td>\n",
       "      <td>0.891403</td>\n",
       "      <td>0.874319</td>\n",
       "      <td>0.945373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.259800</td>\n",
       "      <td>0.163535</td>\n",
       "      <td>0.857760</td>\n",
       "      <td>0.888189</td>\n",
       "      <td>0.872709</td>\n",
       "      <td>0.944312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.259800</td>\n",
       "      <td>0.163174</td>\n",
       "      <td>0.854548</td>\n",
       "      <td>0.890838</td>\n",
       "      <td>0.872316</td>\n",
       "      <td>0.943908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.257500</td>\n",
       "      <td>0.165094</td>\n",
       "      <td>0.855838</td>\n",
       "      <td>0.887017</td>\n",
       "      <td>0.871149</td>\n",
       "      <td>0.943475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.257500</td>\n",
       "      <td>0.163608</td>\n",
       "      <td>0.859661</td>\n",
       "      <td>0.887321</td>\n",
       "      <td>0.873272</td>\n",
       "      <td>0.944356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.257500</td>\n",
       "      <td>0.162173</td>\n",
       "      <td>0.858879</td>\n",
       "      <td>0.892966</td>\n",
       "      <td>0.875591</td>\n",
       "      <td>0.944685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.255900</td>\n",
       "      <td>0.162117</td>\n",
       "      <td>0.861905</td>\n",
       "      <td>0.890274</td>\n",
       "      <td>0.875860</td>\n",
       "      <td>0.944954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.255900</td>\n",
       "      <td>0.162633</td>\n",
       "      <td>0.858216</td>\n",
       "      <td>0.888102</td>\n",
       "      <td>0.872903</td>\n",
       "      <td>0.944506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.255900</td>\n",
       "      <td>0.162177</td>\n",
       "      <td>0.856456</td>\n",
       "      <td>0.889405</td>\n",
       "      <td>0.872620</td>\n",
       "      <td>0.944745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.255900</td>\n",
       "      <td>0.161841</td>\n",
       "      <td>0.859312</td>\n",
       "      <td>0.889535</td>\n",
       "      <td>0.874163</td>\n",
       "      <td>0.944685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.255900</td>\n",
       "      <td>0.161833</td>\n",
       "      <td>0.861298</td>\n",
       "      <td>0.889796</td>\n",
       "      <td>0.875315</td>\n",
       "      <td>0.944924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.255900</td>\n",
       "      <td>0.161358</td>\n",
       "      <td>0.861287</td>\n",
       "      <td>0.890795</td>\n",
       "      <td>0.875792</td>\n",
       "      <td>0.945283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>0.162105</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.888754</td>\n",
       "      <td>0.874141</td>\n",
       "      <td>0.944745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>0.161740</td>\n",
       "      <td>0.860590</td>\n",
       "      <td>0.888841</td>\n",
       "      <td>0.874487</td>\n",
       "      <td>0.944879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.002, 'batch_size': 32, 'weight_decay': 0.1}  =  {'precision': 0.5260070394994134, 'recall': 0.5891371003066141, 'f1': 0.5557851239669421, 'number': 2283}\n",
      "{'learning_rate': 0.002, 'batch_size': 32, 'weight_decay': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4710' max='4710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4710/4710 22:02, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.290302</td>\n",
       "      <td>0.772669</td>\n",
       "      <td>0.818063</td>\n",
       "      <td>0.794719</td>\n",
       "      <td>0.901742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.233114</td>\n",
       "      <td>0.807718</td>\n",
       "      <td>0.844333</td>\n",
       "      <td>0.825620</td>\n",
       "      <td>0.920345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.206741</td>\n",
       "      <td>0.826076</td>\n",
       "      <td>0.860834</td>\n",
       "      <td>0.843097</td>\n",
       "      <td>0.929519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.399400</td>\n",
       "      <td>0.198413</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>0.866348</td>\n",
       "      <td>0.848209</td>\n",
       "      <td>0.931267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.399400</td>\n",
       "      <td>0.185554</td>\n",
       "      <td>0.841312</td>\n",
       "      <td>0.879852</td>\n",
       "      <td>0.860151</td>\n",
       "      <td>0.937304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.399400</td>\n",
       "      <td>0.181788</td>\n",
       "      <td>0.843683</td>\n",
       "      <td>0.871342</td>\n",
       "      <td>0.857289</td>\n",
       "      <td>0.936766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.276600</td>\n",
       "      <td>0.177940</td>\n",
       "      <td>0.844592</td>\n",
       "      <td>0.881155</td>\n",
       "      <td>0.862486</td>\n",
       "      <td>0.938977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.276600</td>\n",
       "      <td>0.171937</td>\n",
       "      <td>0.850507</td>\n",
       "      <td>0.881676</td>\n",
       "      <td>0.865811</td>\n",
       "      <td>0.941801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.276600</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>0.854124</td>\n",
       "      <td>0.884498</td>\n",
       "      <td>0.869046</td>\n",
       "      <td>0.942115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.264700</td>\n",
       "      <td>0.166989</td>\n",
       "      <td>0.857629</td>\n",
       "      <td>0.886974</td>\n",
       "      <td>0.872054</td>\n",
       "      <td>0.942877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.264700</td>\n",
       "      <td>0.164797</td>\n",
       "      <td>0.857861</td>\n",
       "      <td>0.889709</td>\n",
       "      <td>0.873495</td>\n",
       "      <td>0.943370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.264700</td>\n",
       "      <td>0.165603</td>\n",
       "      <td>0.855157</td>\n",
       "      <td>0.884195</td>\n",
       "      <td>0.869433</td>\n",
       "      <td>0.942563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.258700</td>\n",
       "      <td>0.167320</td>\n",
       "      <td>0.851175</td>\n",
       "      <td>0.879375</td>\n",
       "      <td>0.865045</td>\n",
       "      <td>0.941786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.258700</td>\n",
       "      <td>0.166513</td>\n",
       "      <td>0.851727</td>\n",
       "      <td>0.891706</td>\n",
       "      <td>0.871259</td>\n",
       "      <td>0.941772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.258700</td>\n",
       "      <td>0.161893</td>\n",
       "      <td>0.861563</td>\n",
       "      <td>0.887451</td>\n",
       "      <td>0.874316</td>\n",
       "      <td>0.944745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.256800</td>\n",
       "      <td>0.161903</td>\n",
       "      <td>0.861676</td>\n",
       "      <td>0.889101</td>\n",
       "      <td>0.875174</td>\n",
       "      <td>0.944610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.256800</td>\n",
       "      <td>0.156897</td>\n",
       "      <td>0.861479</td>\n",
       "      <td>0.894659</td>\n",
       "      <td>0.877756</td>\n",
       "      <td>0.947136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.256800</td>\n",
       "      <td>0.157313</td>\n",
       "      <td>0.860985</td>\n",
       "      <td>0.890968</td>\n",
       "      <td>0.875720</td>\n",
       "      <td>0.945940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.256800</td>\n",
       "      <td>0.156811</td>\n",
       "      <td>0.858703</td>\n",
       "      <td>0.894312</td>\n",
       "      <td>0.876146</td>\n",
       "      <td>0.946030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.254400</td>\n",
       "      <td>0.158613</td>\n",
       "      <td>0.859029</td>\n",
       "      <td>0.889839</td>\n",
       "      <td>0.874163</td>\n",
       "      <td>0.945148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.254400</td>\n",
       "      <td>0.157172</td>\n",
       "      <td>0.861940</td>\n",
       "      <td>0.889449</td>\n",
       "      <td>0.875478</td>\n",
       "      <td>0.945895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.254400</td>\n",
       "      <td>0.155506</td>\n",
       "      <td>0.862882</td>\n",
       "      <td>0.896266</td>\n",
       "      <td>0.879257</td>\n",
       "      <td>0.946852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.252800</td>\n",
       "      <td>0.155649</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.892445</td>\n",
       "      <td>0.878202</td>\n",
       "      <td>0.946523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.252800</td>\n",
       "      <td>0.156150</td>\n",
       "      <td>0.862639</td>\n",
       "      <td>0.890881</td>\n",
       "      <td>0.876533</td>\n",
       "      <td>0.946538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.252800</td>\n",
       "      <td>0.155603</td>\n",
       "      <td>0.860149</td>\n",
       "      <td>0.892792</td>\n",
       "      <td>0.876167</td>\n",
       "      <td>0.946463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.252900</td>\n",
       "      <td>0.155296</td>\n",
       "      <td>0.864200</td>\n",
       "      <td>0.893356</td>\n",
       "      <td>0.878536</td>\n",
       "      <td>0.946867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.252900</td>\n",
       "      <td>0.155330</td>\n",
       "      <td>0.864294</td>\n",
       "      <td>0.892966</td>\n",
       "      <td>0.878396</td>\n",
       "      <td>0.946747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.252900</td>\n",
       "      <td>0.154742</td>\n",
       "      <td>0.864451</td>\n",
       "      <td>0.894442</td>\n",
       "      <td>0.879191</td>\n",
       "      <td>0.947180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.155578</td>\n",
       "      <td>0.863524</td>\n",
       "      <td>0.891533</td>\n",
       "      <td>0.877305</td>\n",
       "      <td>0.946583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.155165</td>\n",
       "      <td>0.864395</td>\n",
       "      <td>0.892358</td>\n",
       "      <td>0.878154</td>\n",
       "      <td>0.946912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.002, 'batch_size': 32, 'weight_decay': 0.01}  =  {'precision': 0.530373831775701, 'recall': 0.5965834428383706, 'f1': 0.5615337043908473, 'number': 2283}\n"
     ]
    }
   ],
   "source": [
    "# пробегаемся по сетке, фиксируем результаты обучения в массивчик\n",
    "results = []\n",
    "for i in process(grid)[:]:\n",
    "    print(i)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list))\n",
    "    trainer = get_tainer(i, model, tokenized_datasets, compute_metrics, data_collator)\n",
    "    trainer.train()\n",
    "    \n",
    "    \n",
    "    predictions, labels, _ = trainer.predict(tokenized_datasets[\"test\"])\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    rr = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    results.append([i, rr])\n",
    "    print(i, ' = ', rr['ORG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b08d810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Просмотр результатов подбора параметров\n",
    "\n",
    "\n",
    "rr = []\n",
    "for i in results:\n",
    "    p = i[1]['ORG']\n",
    "    p['params'] = str(i[0])\n",
    "    rr.append(p)\n",
    "df_f1 = pd.DataFrame(rr).sort_values(by=['f1'])\n",
    "\n",
    "display(HTML(df_f1.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c973979b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>number</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.344359</td>\n",
       "      <td>0.410425</td>\n",
       "      <td>0.374500</td>\n",
       "      <td>2283</td>\n",
       "      <td>{'learning_rate': 5e-05, 'batch_size': 32, 'weight_decay': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.344726</td>\n",
       "      <td>0.410863</td>\n",
       "      <td>0.374900</td>\n",
       "      <td>2283</td>\n",
       "      <td>{'learning_rate': 5e-05, 'batch_size': 32, 'weight_decay': 0.01}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.345970</td>\n",
       "      <td>0.411739</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>2283</td>\n",
       "      <td>{'learning_rate': 5e-05, 'batch_size': 32, 'weight_decay': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.451429</td>\n",
       "      <td>0.519054</td>\n",
       "      <td>0.482885</td>\n",
       "      <td>2283</td>\n",
       "      <td>{'learning_rate': 0.0002, 'batch_size': 32, 'weight_decay': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.451502</td>\n",
       "      <td>0.519930</td>\n",
       "      <td>0.483306</td>\n",
       "      <td>2283</td>\n",
       "      <td>{'learning_rate': 0.0002, 'batch_size': 32, 'weight_decay': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.451674</td>\n",
       "      <td>0.519930</td>\n",
       "      <td>0.483405</td>\n",
       "      <td>2283</td>\n",
       "      <td>{'learning_rate': 0.0002, 'batch_size': 32, 'weight_decay': 0.01}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.526007</td>\n",
       "      <td>0.589137</td>\n",
       "      <td>0.555785</td>\n",
       "      <td>2283</td>\n",
       "      <td>{'learning_rate': 0.002, 'batch_size': 32, 'weight_decay': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.530374</td>\n",
       "      <td>0.596583</td>\n",
       "      <td>0.561534</td>\n",
       "      <td>2283</td>\n",
       "      <td>{'learning_rate': 0.002, 'batch_size': 32, 'weight_decay': 0.01}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.531128</td>\n",
       "      <td>0.597898</td>\n",
       "      <td>0.562539</td>\n",
       "      <td>2283</td>\n",
       "      <td>{'learning_rate': 0.002, 'batch_size': 32, 'weight_decay': 0.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
